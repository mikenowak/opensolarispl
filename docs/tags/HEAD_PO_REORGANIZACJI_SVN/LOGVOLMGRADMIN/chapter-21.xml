<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML//EN" "docbook.dtd"[
	<!ENTITY % xinclude SYSTEM "xinclude.mod">
	%xinclude;
]>

<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="best-practices-1">



<title>Best Practices for Solaris Volume Manager</title>
<toc>
<para>This chapter provides general best practices information from a real-world storage
scenario using Solaris Volume Manager. In this chapter, you will see a typical configuration,
followed by an analysis, followed by a recommended (“Best Practices”)
configuration to meet the same needs.</para>
<para>This chapter includes the following information:</para>
<itemizedlist>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-21.xml" targetptr="best-practices-small-servers">Deploying Small Servers</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-21.xml" targetptr="best-practices-2">Using Solaris Volume Manager With Networked Storage Devices</olink>
</para>
</listitem>
</itemizedlist>
</toc>
<sect1 xml:id="best-practices-small-servers">
<title>Deploying Small Servers</title>
<indexterm xml:id="indexterm-216">
<primary>small servers</primary>
<secondary>overview of deploying</secondary>
</indexterm>
<para>Distributed computing environments, often need to deploy similar or identical
servers at multiple locations. These environments include ISPs, geographically distributed
sales offices, and telecommunication service providers. Servers in a distributed computing
environment might provide some of the following services:</para>
<itemizedlist>
<listitem>
<para>Router or firewall services</para>
</listitem>
<listitem>
<para>Email services</para>
</listitem>
<listitem>
<para>DNS caches</para>
</listitem>
<listitem>
<para>Usenet (Network News) servers</para>
</listitem>
<listitem>
<para>DHCP services</para>
</listitem>
<listitem>
<para>Other services best provided at a variety of locations</para>
</listitem>
</itemizedlist>
<para>These small servers have several characteristics in common:</para>
<itemizedlist>
<listitem>
<para>High-reliability requirements</para>
</listitem>
<listitem>
<para>High-availability requirements</para>
</listitem>
<listitem>
<para>Routine hardware and performance requirements</para>
</listitem>
</itemizedlist>
<para>As a starting point, consider a <trademark>Netra</trademark> server with a single
SCSI bus and two internal disks. This off-the-shelf configuration is a good starting
point for distributed servers. Solaris Volume Manager could easily be used to mirror
some or all of the slices, thus providing redundant storage to help guard against
disk failure. See the following figure for an example of this small system configuration.</para>
<figure xml:id="best-practices-fig-4">

<title>Small System Configuration</title>
<mediaobject>
<imageobject>
<imagedata fileref="figures/best-practices-sm-sys-1.gif"/>
</imageobject>
<textobject>
<simpara>Diagram shows how a single system with a single SCSI controller
can mirror two disks for redundant storage. </simpara>
</textobject>
</mediaobject>
</figure>
<para>This configuration might include mirrors for the root (<literal>/</literal>), <literal>/usr</literal>, <literal>swap</literal>, <literal>/var</literal>, and <literal>/export</literal> file systems, plus state database replicas (one per disk). As such, a failure
of either side of any of the mirrors would not necessarily result in system failure.
Also, up to five discrete failures could possibly be tolerated. However, the system
is not sufficiently protected against disk or slice failure. A variety of potential
failures could result in a complete system failure, requiring operator intervention. </para>
<para>While this configuration does help provide some protection against catastrophic
disk failure, it exposes key possible single points of failure:</para>
<itemizedlist>
<listitem>
<para>The single SCSI controller represents a potential point of failure.
If the controller fails, the system is down, pending replacement of the part. </para>
</listitem>
<listitem>
<para>The two disks do not provide adequate distribution of state database
replicas. The majority consensus algorithm requires that half of the state database
replicas be available for the system to continue to run. This algorithm also requires
half plus one replica for a reboot. So, if one state database replica were on each
disk and one disk or the slice that contains the replica failed, the system could
not reboot. As a result a mirrored root (<filename>/</filename>) file system would
become ineffective. If two or more state database replicas were on each disk, a single
slice failure would likely not be problematic. However, a disk failure would still
prevent a reboot. If different number of replicas were on each disk, one disk would
have more than half and one disk would have fewer than half. If the disk with fewer
replicas failed, the system could reboot and continue. However, if the disk with more
replicas failed, the system would immediately panic. </para>
</listitem>
</itemizedlist>
<para>A “Best Practices” approach would be to modify the configuration
by adding one more controller and one more hard drive. The resulting configuration
would be far more resilient. </para>
</sect1>
<sect1 xml:id="best-practices-2">
<title>Using Solaris Volume Manager With Networked Storage Devices</title>
<indexterm xml:id="indexterm-217">
<primary>Solaris Volume Manager</primary>
<secondary>networked storage devices and</secondary>
</indexterm>
<para>Solaris Volume Manager works well with networked storage devices, particularly those
devices that provide configurable RAID levels and flexible options. Usually, the combination
of Solaris Volume Manager and such devices can result in performance and flexibility that
is superior to either product alone. </para>
<para>Generally, do not establish Solaris Volume Manager's RAID-5 volumes on any hardware
storage devices that provide redundancy (for example, RAID-1 and RAID-5 volumes).
Unless you have a very unusual situation, performance suffers. Also, you will gain
very little in terms of redundancy or higher availability.</para>
<para>Configuring underlying hardware storage devices with RAID-5 volumes, on the
other hand, is very effective. Doing so provides a good foundation for Solaris Volume Manager volumes.
Hardware RAID-5 provides additional redundancy for Solaris Volume Manager's RAID-1 volumes,
soft partitions, or other volumes.</para>
<note>

<para>Do not configure similar software and hardware devices. For example, do
not build software RAID-1 volumes on top of hardware RAID-1 devices. Configuring similar
devices in hardware and software results in performance penalties without offsetting
any gains in reliability. </para>
</note>
<para>Solaris Volume Manager's RAID-1 volumes that are built on underlying hardware storage
devices are not RAID-1+0. Solaris Volume Manager cannot understand the underlying storage
well enough to offer RAID-1+0 capabilities.</para>
<para>Configuring soft partitions on top of Solaris Volume Manager RAID-1 volume, built in
turn on a hardware RAID-5 device, is a very flexible and resilient configuration.</para>
</sect1>
</chapter>
