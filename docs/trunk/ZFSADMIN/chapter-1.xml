<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML//EN" "docbook.dtd"[
	<!ENTITY % xinclude SYSTEM "xinclude.mod">
	%xinclude;
]>

<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="zfsover-1">



<title>System plików ZFS (Wprowadzenie)</title>
<toc>
<para>Ten rozdział zawiera przegląd możliwości oraz korzyści związanych z systemem plików ZFS. Wyjaśnia także podstawową terminologię pojawiającą się w następnych rozdziałach.</para>
<para>W tym rozdziale znajdują się następujące podrozdziały:</para>
<itemizedlist>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gbscy">Co nowego w ZFS-ie?</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="zfsover-2">Czym jest ZFS?</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="ftyue">Terminologia</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gbcpt">Nazewnictwo elementów składowych ZFS-a</olink>
</para>
</listitem>
</itemizedlist>
</toc>
<sect1 xml:id="gbscy">
<title>Co nowego w ZFS-ie?</title>
<para>Nowe cechy dodane do systemu plików ZFS.</para>
<itemizedlist>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gevnp">Rekursywna zmiana nazw obrazów ZFS (<command>zfs rename</command> <option>r</option>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gevpi">Kompresja GZIP dla systemu plików ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gevpg">Zachowywanie wielokrotnych kopii danych użytkownika</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gebws">Poprawione wyjście polecenia <command>zpool status</command></olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gebwq">Poprawienie funkcjonalności ZFS oraz Solaris iSCSI</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gebwp">Rozszerzenia w udostępnianiu systemów plików ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gdswe">Historia poleceń ZFS (<command>zpool history</command>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gdswf">Rozszerzenie parametrów ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gdsvh">Drukowanie wszystkich informacji o systemie plików ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gdsup">Nowa opcja <command>zfs receive</command> <option>
F</option> </olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gdfdt">Rekursywne obrazy ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcviu">RAID-Z o podwójnej przystości (<literal>raidz2</literal>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcvdm">Hot Spares w pulach nośników danych ZFS</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcvgc">Podmiana systemu plików ZFS na jego klon (<command>zfs promote</command>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcvit">Uaktualnianie pul nośników danych ZFS (<command>zpool upgrade</command>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcsxk">Używanie ZFS do klonowanie nieglobalnych stref oraz inne dodatki</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gciui">Zmieniono nazwy komend ZFS Backup i Restore</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcitn">Odzyskiwanie zniszczonych pul nośników danych</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcfhy">ZFS został zintegrowany z zarządzaniem awariami</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcfiw">Nowa komenda <command>zpool clear</command> </olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcajn">Skrócony format ACL-i NFSv4</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gcakl">Narzędzie do monitorowania systemu plików (<command>fsstat</command>)</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-1.xml" targetptr="gbsbp">Zarządzanie ZFS przez WWW</olink>
</para>
</listitem>
</itemizedlist>
<sect2 xml:id="gevnp">
<title>Rekursywna zmiana nazw obrazów ZFS (<command>zfs rename</command> <option>
r</option>)</title>
<para>
<emphasis role="strong">Solaris Express Developer Edition 5/07:</emphasis> 
Korzystająć z komendy <command>zfs rename</command> <option>
r</option> można rekursywnie zmienić nazwy obrazów ZFS (ang. snapshot). </para>
<para>Przykładowo wykonany zostanie obraz systemów plików ZFS.</para>
<screen># <userinput>zfs snapshot -r users/home@today</userinput>
# <userinput>zfs list</userinput>
NAME                     USED  AVAIL  REFER  MOUNTPOINT
users                    216K  16.5G    20K  /users
users/home                76K  16.5G    22K  /users/home
users/home@today            0      -    22K  -
users/home/markm          18K  16.5G    18K  /users/home/markm
users/home/markm@today      0      -    18K  -
users/home/marks          18K  16.5G    18K  /users/home/marks
users/home/marks@today      0      -    18K  -
users/home/neil           18K  16.5G    18K  /users/home/neil
users/home/neil@today       0      -    18K  -</screen>
<para>Następnie zmienione zostaną nazwy.</para>
<screen># <userinput>zfs rename -r users/home@today @yesterday</userinput>
# <userinput>zfs list</userinput>
NAME                         USED  AVAIL  REFER  MOUNTPOINT
users                        216K  16.5G    20K  /users
users/home                    76K  16.5G    22K  /users/home
users/home@yesterday            0      -    22K  -
users/home/markm              18K  16.5G    18K  /users/home/markm
users/home/markm@yesterday      0      -    18K  -
users/home/marks              18K  16.5G    18K  /users/home/marks
users/home/marks@yesterday      0      -    18K  -
users/home/neil               18K  16.5G    18K  /users/home/neil
users/home/neil@yesterday       0      -    18K  -</screen>
<para>Nazwy można zmienić rekursywnie tylko obrazom. </para>
<para>Więcej informacji o obrazach ZFS w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbciq">Przegląd obrazów ZFS</olink> oraz ten wpis w blogu:</para>
<para>
<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:type="url" xlink:href="http://blogs.sun.com/mmusante/entry/rolling_snapshots_made_easy">http://blogs.sun.com/mmusante/entry/rolling_snapshots_made_easy</link>
</para>
</sect2>
<sect2 xml:id="gevpi">
<title>Kompresja GZIP w ZFS</title>
<para>
<emphasis role="strong">Solaris Express Developer Edition 5/07:</emphasis> W tym wydaniu Solarisa
dostępne są parametry <literal>gzip</literal> oraz <literal>lzjb</literal> włączające odpowiednią kompresję 
w systemie plików ZFS. Można wskazać domyślną kompresję <literal>gzip</literal> lub <literal>gzip-</literal>
<replacable>N</replacable>, gdzie <replaceable>N</replaceable> równe jest od 1 do 9. Na przykład:</para>
<screen># zfs create -o compression=gzip users/home/snapshots
# zfs get compression users/home/snapshots
NAME                  PROPERTY     VALUE            SOURCE
users/home/snapshots  compression  gzip             local
# zfs create -o compression=gzip-9 users/home/oldfiles
# zfs get compression users/home/oldfiles
NAME                  PROPERTY     VALUE           SOURCE
users/home/oldfiles   compression  gzip-9          local</screen>
<para>Więcej informacji o ustawianiu właściwości ZFS w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gazsp">Ustawianie właściwości ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gevpg">
<title>Przechowywanie wielu kopii danych użytkownika ZFS</title>
<para>
<emphasis role="strong">Solaris Express Developer Edition 5/07:</emphasis> 
Metadane ZFS są automatycznie równocześnie przechowywane wiele razy na kilku dyskach w puli, jeśli istnieje taka możliwość. Są to tak zwane <emphasis>bloki ditto</emphasis>.</para>
<para>W tej wersji Solarisa można nakazać również równoczesne przechowywanie kilku kopii danych użytkowników za pomocą komendy <command>zfs set copies</command>.
Na przykład:</para>
<screen># <userinput>zfs set copies=2 users/home</userinput>
# <userinput>zfs get copies users/home</userinput>
NAME        PROPERTY  VALUE       SOURCE
users/home  copies    2           local</screen>
<para>Dostępne wartości to 1, 2 i 3. domyślna wartość to 1. Kopie te są dodatkiem do redundantności zapewnianej przez mirror lub RAID-Z.</para>
<para>Zyski z wielokrotnego przechowywania kopii danych:</para>
<itemizedlist>
<listitem>
<para>Polepsza odporność danych na błedne odczyty bloków, wynikłe na przykład z uszkodzenia nośnika (psucie bitów) we wszystkich konfiguracjach ZFS.</para>
</listitem>
<listitem>
<para>Umożliwia ochronę danych nawet w przypadku, gdy dostępny jest tylko jeden dysk w puli.</para>
</listitem>
<listitem>
<para>Umożlwia na precyzowanie zasad ochrony danych na poziomie systemu plików, niezależnie od możliwości puli.</para>
</listitem>
</itemizedlist>
<para>Zależnie od rozłożenia bloków ditto w puli nośników danych, równoczesne kopie danych mogą być przechowywane na tym samym dysku. Uszkodzenie całego dysku może spowodować niedostępność wszystkich bloków ditto.</para>
<para>Użycie bloków ditto można rozważać przy błednych utworzeniu puli bez redundancji danych, gdy redundadncja taka jest jednak wymagana.</para>
<para>Więcej informacji o tym, jak użycie wielokrotnych kopii w systemie z pulą składającą się z jednego dysku i z wielu dysków wpływa na bezpieczeństwo danych w tym blogu:</para>
<para>
<link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:type="text" xlink:href="http://blogs.sun.com/relling/entry/zfs_copies_and_data_protection">http://blogs.sun.com/relling/entry/zfs_copies_and_data_protection</link>
</para>
<para>Więcej informacji o ustawianiu właściwości ZFS w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gazsp">Ustawianie właściwości ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gebws">
<title>Poprawiony wydruk komendy <command>zpool status</command></title>
<para>
<emphasis role="strong">Solaris Express 1/07:</emphasis> 
Za pomocą komendy <command>zpool status</command> <option>
v</option> można wydrukować listę plików z nieodwracalnymi błędami. Poprzednio należało użyć komendy <command>find</command> <option>
inum</option> do zidentyfikowania plików na podstawie listy inode'ów.</para>
<para>Więcej informacji o drukowaniu listy plików z nieodwracalnymi błędami w <olink remap="external" targetdoc="chapter-9.xml" targetptr="gbctx">Naprawianie uszkodzonych plików i katalogów</olink>.</para>
</sect2>
<sect2 xml:id="gebwq">
<title>ZFS i ulepszenia Solaris iSCSI</title>
<para>
<emphasis role="strong">Solaris Express, Developer Edition 2/07:</emphasis> 
W tej wersji Solarisa można tworzyć wolumeny ZFS jako cele Solaris iSCSI ustawiając dla wolumenu parametr <literal>shareiscsi</literal>. Jest to wygodna metoda szybkiego konfigurowania celów Solaris iSCSI. Na przykład:</para>
<screen># zfs create -V 2g tank/volumes/v2
# zfs set shareiscsi=on tank/volumes/v2
# iscsitadm list target
Target: tank/volumes/v2
    iSCSI Name: iqn.1986-03.com.sun:02:984fe301-c412-ccc1-cc80-cf9a72aa062a
    Connections: 0</screen>
<para>Po stworzeniu celu iSCSI należy skonfigurować inicjatora iSCSI. Więcej informacji na ten temat w <olink remap="external" targetdoc="819-2723" targetptr="fmvcd">Rozdział 14, <citetitle remap="chapter">Configuring Solaris
iSCSI Targets and Initiators (Tasks),</citetitle> in <citetitle remap="book">System
Administration Guide: Devices and File Systems</citetitle>
</olink>.</para>
<para>Więcej informacji o zarządzaniu wolumenami ZFS jako celami iSCSI w <olink remap="external" targetdoc="chapter-8.xml" targetptr="gechv">Używanie wolumenu ZFS jako celu Solaris iSCSI</olink>.</para>
</sect2>
<sect2 xml:id="gebwp">
<title>Ulepszenia współdzielenia systemu plików ZFS</title>
<para>
<emphasis role="strong">Solaris Express, Developer Edition 2/07:</emphasis> 
W tej wersji Solarisa poprawiono proces współdzielenia systemów plików. Wprawdzie nie ma konieczności poprawiania plików konfiguracyjnych, jak na przykład <filename>/etc/dfs/dfstab</filename>, można użyć komendy <command>sharemgr</command> do zarządzania właściwościami współdzielenia ZFS. Komenda <command>sharemgr</command> umożliwia zarządzanie grupami współdzielenia. Systemy współdzielone ZFS są automatycznie częścią grupy <literal>zfs</literal>.</para>
<para>Tak jak w poprzednich wersjach, można ustawić właściwość ZFS <literal>sharenfs</literal> w celu współdzielenia go. Na przykład:</para>
<screen># zfs set sharenfs=on tank/home</screen>
<para>Można też użyć nowej komendy <command>sharemgr</command> <command>add-share</command>. Na przykład:</para>
<screen># sharemgr add-share -s tank/data zfs
# sharemgr show -vp zfs
zfs nfs=()
    zfs/tank/data
          /tank/data
          /tank/data/1
          /tank/data/2
          /tank/data/3</screen>
<para>Można wtedy używać komendy <command>sharemgr</command> do zarządzania udziałami ZFS. W poniższym przykładzie na udziale ZFS ustawiono właściwość <literal>nosuid</literal>. Należy poprzedzić ścieżni ZFS nazwą grupy <literal>/zfs</literal>.</para>
<screen># sharemgr set -P nfs -p nosuid=true zfs/tank/data
# sharemgr show -vp zfs
zfs nfs=()
    zfs/tank/data nfs=(nosuid="true")
          /tank/data
          /tank/data/1
          /tank/data/2
          /tank/data/3</screen>
<para>Więcej informacji w <olink remap="external" targetdoc="819-2240" targetptr="sharemgr-1m">
<citerefentry>
<refentrytitle>sharemgr</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gdswe">
<title>Historia poleceń komendy ZFS (<command>zpool history</command>)</title>
<para>
<emphasis role="strong">Solaris Express 12/06:</emphasis> 
W tej wersji Solarisa ZFS automatycznie zapisuje udane polecenia <command>zfs</command> i <command>zpool</command>, które zmieniają stan puli. Na przykład:</para>
<screen># <userinput>zpool history</userinput>
History for 'newpool':
2007-04-25.11:37:31 zpool create newpool mirror c0t8d0 c0t10d0
2007-04-25.11:37:46 zpool replace newpool c0t10d0 c0t9d0
2007-04-25.11:38:04 zpool attach newpool c0t9d0 c0t11d0
2007-04-25.11:38:09 zfs create newpool/user1
2007-04-25.11:38:15 zfs destroy newpool/user1

History for 'tank':
2007-04-25.11:46:28 zpool create tank mirror c1t0d0 c2t0d0 mirror c3t0d0 c4t0d0</screen>
<para>Umożliwia to pracownikom Suna na odtworzenie <emphasis>dokładnej</emphasis> historii wykonanych poleceń, ułatwiając poszukiwanie błędu.</para>
<para>Można wskazać konretną pulę komendzie <command>zpool history</command>. Na przykład:</para>
<screen># <userinput>zpool history newpool</userinput>
History for 'newpool':
History for 'newpool':
2007-04-25.11:37:31 zpool create newpool mirror c0t8d0 c0t10d0
2007-04-25.11:37:46 zpool replace newpool c0t10d0 c0t9d0
2007-04-25.11:38:04 zpool attach newpool c0t9d0 c0t11d0
2007-04-25.11:38:09 zfs create newpool/user1
2007-04-25.11:38:15 zfs destroy newpool/user1</screen>
<para>Możliwości historii poleceń są następujące:</para>
<itemizedlist>
<listitem>
<para>Historii nie można wyłączyć.</para>
</listitem>
<listitem>
<para>Historia jest zapisywana na dysku, co oznacza, że restart systemu jej nie wymazuje.</para>
</listitem>
<listitem>
<para>Minimalna wielkość bufora to 128 Kb, maksymalna to 32 MB.</para>
</listitem>
<listitem>
<para>W mniejszych pulach wielkość jest ograniczona do 1% wielkości puli, gdzie <replaceable>wielkość</replaceable> jest okreslana w momencie tworzenia puli.</para>
</listitem>
<listitem>
<para>Nie wymaga administracji, co oznacza, że nie ma konieczności zmiany wielkości logu lub jego lokacji.</para>
</listitem>
</itemizedlist>
<para>Obecnie komenda <command>zpool history</command> nie drukuje <replaceable>user-ID</replaceable>, <replaceable>hostname</replaceable> ani <replaceable>zone-name</replaceable>.</para>
<para>Więcej informacji o rozwiązywaniu problemów z ZFS w <olink remap="external" targetdoc="chapter-9.xml" targetptr="gbbuw">Identyfikacja problemów z ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gdswf">
<title>Ulepszenia właściwości ZFS </title>
<sect3 xml:id="gebwr">
<title>Właściwość ZFS <literal>xattr</literal></title>
<para>
<emphasis role="strong">Solaris Express 1/07:</emphasis> 
Komendą <literal>xattr</literal> można włączać i wyłączać rozszerzone atrybuty ZFS dla każdego systemu plików. Domyślnie rozszerzone atrybuty są włączone. Więcej na temat rozszerzonych atrybutów ZFS w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gazss">Wprowadzenie do właściwości ZFS</olink>.</para>
</sect3>
<sect3 xml:id="gdswd">
<title>Właściwość ZFS <command>canmount</command></title>
<para>
<emphasis role="strong">Solaris Express 10/06:</emphasis>
Nowa właściwość <command>canmount</command> umożliwia decydowanie, czy dany dataset może być montowany za pomocą komendy <command>zfs mount</command>. Więcej informacji w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gdrcf">Właściwość <command>canmount</command></olink>.</para>
</sect3>
<sect3 xml:id="gdsus">
<title>Właściwości użytkowników ZFS</title>
<para>
<emphasis role="strong">Solaris Express 10/06:</emphasis>
Oprócz standardowych właściwości wewnętrznych, pozwalających na eksport wewnętrznych statystyk i kontrolę zachowania ZFS, istnieją też właściwości użytkowników. Nie mają wpływu na działanie ZFS, ale można z nich korzystać do oznaczania datasetów w sposób zrozumiały w ich kontekście. </para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gdrcw">Właściwości użytkownika ZFS</olink>.</para>
</sect3>
<sect3 xml:id="gdsvx">
<title>Ustalanie właściwości podczas tworzenia systemów plików ZFS</title>
<para>
<emphasis role="strong">Solaris Express 10/06:</emphasis> 
W tej wersji Solarisa, oprócz dotychczasowej metody ustalania właściwości po utworzeniu systemu plików, można je także ustalić podczas jego tworzenia.</para>
<para>Poniższe przykłady ilustrują odpowiednie składnie:</para>
<screen># <userinput>zfs create tank/home</userinput>
# <userinput>zfs set mountpoint=/export/zfs tank/home</userinput>
# <userinput>zfs set sharenfs=on tank/home</userinput>
# <userinput>zfs set compression=on tank/home</userinput>
</screen>
<screen># <userinput>zfs create -o mountpoint=/export/zfs -o sharenfs=on -o compression=on tank/home</userinput>
</screen>
</sect3>
</sect2>
<sect2 xml:id="gdsvh">
<title>Drukowanie pełnej informacji o systemie plików ZFS</title>
<para>
<emphasis role="strong">Solaris Express 10/06:</emphasis>
W tej wersji Solarisa można wydrukować pełną informację o systemie plików ZFS za pomocą komendy <command>zfs get</command> bez parametrów. W poprzednich wersjach dane te nie były dostępne za pomocą komendy <command>zfs get</command>.</para>
<para>Na przykład:</para>
<screen># <userinput>zfs get -s local all</userinput>
tank/home               atime          off                    local
tank/home/bonwick       atime          off                    local
tank/home/marks         quota          50G                    local</screen>
</sect2>
<sect2 xml:id="gdsup">
<title>Nowa opcja <command>zfs receive</command> <option>
F</option></title>
<para>
<emphasis role="strong">Solaris Express 10/06:</emphasis> 
W tej wersji Solarisa, komendą <command>zfs receive</command> <option>
F</option> można wymusić powrót do ostatniego obrazu przed wykonaniem <command>zfs receive</command>. Może to być konieczne, gdy system plików zmieni się między rollbackiem a rozpoczęciem <command>zfs receive</command>. </para>
<para>For more information, see <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbimy">Restoring a ZFS Snapshot</olink>.</para>
</sect2>
<sect2 xml:id="gdfdt">
<title>Rekursywne obrazy ZFS</title>
<para>
<emphasis role="strong">Solaris Express 8/06:</emphasis>
 Podczas wykonywania komendy <command>zfs snapshot</command> można podać opcję <option>
r</option>, która powoduje rekursywne wykonywanie obrazów - tworzone są obrazy dla wszystkich systemów plików w dół hierarchii systemów plików. Dodatkowo można podać opcję <option>
r</option> podczas niszczenie obrazu, co powoduje rekursywne niszczenie obrazów.</para>
<para>Obrazy rekursywne tworzone są bardzo szybko, jako jedna atomiczna operacja. Tworzone są wszystkie równocześnie, lub wcale. Zaletą takiego rozwiązania jest, ze wszystkie obrazy wykonywane są dokładnie w tym sammym momencie, nawet na przstrzeni wielu systemów plików. </para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbcya">Tworzenie i niszczenie obrazów ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gcviu">
<title>RAID-Z o podwójnej parzystości (<literal>raidz2</literal>)</title>
<para>
<emphasis role="strong">Solaris Express 7/06:</emphasis>
Konfiguracja RADI-Z może teraz mieć pojedynczą lub podwójną parzystość, co oznacza odporność na awarię jednego lub dwóch dysków w puli. Podwójną parzystość wskazuje się przez podanie parametru <literal>raidz2</literal>, natomiast pojedynczą parzystość można wybrać za pomocą <literal>raidz</literal> lub <literal>raidz1</literal>.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gcvjg">Tworzenie pul nośników danych RAID-Z</olink> or <olink remap="external" targetdoc="819-2240" targetptr="zpool-1m">
<citerefentry>
<refentrytitle>zpool</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gcvdm">
<title>Hot spares w pulach nośników danych ZFS</title>
<para>
<emphasis role="strong">Solaris Express 7/06:</emphasis> 
Paramets Hot Spares ZFS-a pozwala na wskazanie dysków, którymi można zastąpić uszkodzone urządzenia w jednej lub więcej pulach nośników danych. Po wskazaniu urządzenia jako <emphasis>hot spare</emphasis>, przejmuje ono automatycznie rolę uszkodzonego aktywnego dysku. Można też takiej zamiany dokonać ręcznie.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gcvcw">Wskazywanie Host Spares w puli nośników danych</olink> oraz <olink remap="external" targetdoc="819-2240" targetptr="zpool-1m">
<citerefentry>
<refentrytitle>zpool</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gcvgc">
<title>Użycie klonu ZFS do zastąpnienia systemu plików (<command>zfs promote</command>)</title>
<para>
<emphasis role="strong">Solaris Express 7/06:</emphasis> Komenda <command>zfs promote</command> pozwala podmienić system plików ZFS na jego klon. Pozwala to na przykład na wykonanie testów na alternatywnym systemie plików a później uczynienie go domyślnym.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gcvfl">Użycie klonu ZFS do zastąpnienia systemu plików</olink> oraz <olink remap="external" targetdoc="819-2240" targetptr="zfs-1m">
<citerefentry>
<refentrytitle>zfs</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gcvit">
<title>Uaktualnianie pul nośników danych ZFS (<command>zpool
upgrade</command>)</title>
<para>
<emphasis role="strong">Solaris Express 6/06:</emphasis> Pule nośników danych można uaktualnić do nowszej wersji, aby wykorzystać nowe możliwości ZFS. Pozwala na to komenda <command>zpool upgrade</command>. Komendą <command>zpool status</command> można sprawdzić wersję ZFS.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gcikw">Uaktualnianie pul nośników danych ZFS</olink> orazd <olink remap="external" targetdoc="819-2240" targetptr="zpool-1m">
<citerefentry>
<refentrytitle>zpool</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
<para>Przed użyciem konsoli administracyjnej ZFS (ang. ZFS Administration console) na systemie ze starszą wersją puli, koniecznie należy uaktualnić pule przed użyciem konsoli. Konieczność uaktualnienia pul można sprawdzić komendą <command>zpool status</command>. Więcej informacji w <olink remap="internal" targetdoc="chapter-1.xml" targetptr="gbsbp">Zarządzanie ZFS przez WWW</olink>.</para>
</sect2>
<sect2 xml:id="gcsxk">
<title>Używanie ZFS-a do powielania stref (ang. zone) innych niż globalna i inne ulepszenia</title>
<para>
<emphasis role="strong">Solaris Express 6/06:</emphasis> Jeżeli wzorcowy parametr <literal>zonepath</literal> i docelowy <literal>zonepath</literal> znajdują się na ZFS-ie i dodatkowo w tej samej puli ZFS-owej, polecenie <command>zoneadm clone</command> automatycznie użyje funkcjonalności klonowania systemu plików ZFS w celu utworzenia sklonowanej strefy. Oznacza to, że polecenie <command>zoneadm clone</command> robi obraz (snapshot) systemu plików wskazywanego przez źródłowy parametr <literal>zonepath</literal> i ustawia go jako docelowy.
Obraz ten jest nazywany w notacji <literal>SUNWzoneX</literal>, gdzie <literal>X</literal> jest unikatowym identyfikatorem używanym do rozróżnienia poszczególnych obrazów. Parametr <literal>zonepath</literal> docelowej strefy jest używany jako nazwa sklonowanego systemu plików ZFS. Tworzona jest programowa inspekcja poprawności obrazu, aby mógł on zostać później użyty przez system. Nadal istnieje możliwość skopiowania parametru źródłowego ZFS <literal>zonepath</literal> zamiast klonu ZFS, jeśli zajdzie taka potrzeba.</para>
<para>Aby umożliwić kilkukrotnie klonowanie stref dodano nowy parametr polecenia <command>zoneadm</command>, pozwalający na określenie, iż powinien zostać użyty istniejący obraz. Wykonywana jest inspekcja poprawności obrazu, aby mógł on zostać później użyty przez system. Dodatkowo proces instalacyjny strefy umie teraz wykrywać kiedy system plików ZFS może być stworstrefy dla strefy, a proces deinstalacyjny potrafi sprawdzić, czy system plików ZFS w strefie może zostać usunięty. Kroki te są wykonywane automatycznie przez polecenie <command>zoneadm</command>.</para> 
<para>Nie należy wykorzystywać opcji tworzenie obrazów ZFS w celu klonowania strefy.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="819-2450">
<citetitle remap="book">System Administration Guide: Solaris Containers-Resource Management
and Solaris Zones</citetitle>
</olink>.</para>
</sect2>
<sect2 xml:id="gciui">
<title>Komendy ZFS-a do tworzenia kopii zapasowych i odtwarzania systemu plików mają zmienioną nazwę</title>
<para>
<emphasis role="strong">Solaris Express 5/06:</emphasis> W tym wydaniu Solarisa polecenia <command>zfs backup</command> oraz <command>zfs restore</command> zostały przemianowane na <command>zfs send</command> i <command>zfs receive</command>, żeby bardziej precyzyjnie opisywały swoją funkcję. Rolą tych poleceń jest zapis i odtworzenie strumienia danych ZFS-a.</para>
<para>Więcej informacji o tych poleceniach w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbchx">Zapisywanie i odzyskiwanie danych ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gcitn">
<title>Odzyskiwanie zniszczonych pul</title>
<para>
<emphasis role="strong">Solaris Express 5/06:</emphasis> To wydanie wprowadziło polecenie <command>zpool import</command> <option>D</option>, które umożliwia odtworzenie pul zniszczonych wcześniej poleceniem <command>zpool destroy</command>.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gcfhw">Odzyskiwanie zniszczonych danych ZFS</olink>.</para>
</sect2>
<sect2 xml:id="gcfhy">
<title>ZFS został zintegrowany z "Fault Manager"</title>
<para>
<emphasis role="strong">Solaris Express 4/06:</emphasis> Wydanie to zawiera zintegrowany silnik diagnostyczny ZFS, który jest zdolny do diagnozowania oraz raportowania awarii pul i urządzeń. Sumy kontrolne, I/O, błędy puli i urządzeń związane z awariami urządzeń i pul są również raportowane.</para>
<para>Silnik diagnostyczny nie prognozuje na podstawie analizy sum kontrolnych oraz błędów I/O, umie jednak prognozować na podstawie analizy błędu.</para>
<para>W przypadku awarii ZFS może pojawić się błąd podobny do poniższego <command>fmd</command>:</para>
<screen remap="wide">SUNW-MSG-ID: ZFS-8000-D3, TYPE: Fault, VER: 1, SEVERITY: Major
EVENT-TIME: Fri Mar 10 11:09:06 MST 2006
PLATFORM: SUNW,Ultra-60, CSN: -, HOSTNAME: neo
SOURCE: zfs-diagnosis, REV: 1.0
EVENT-ID: b55ee13b-cd74-4dff-8aff-ad575c372ef8
DESC: A ZFS device failed.  Refer to http://sun.com/msg/ZFS-8000-D3 for more information.
AUTO-RESPONSE: No automated response will occur.
IMPACT: Fault tolerance of the pool may be compromised.
REC-ACTION: Run 'zpool status -x' and replace the bad device.</screen>
<para>Poprzez zapoznanie się z rekomendowanymi krokami, które będą przedstawione przez polecenie <command>zpool status</command>, szybko będzie można zidentyfikować i naprawić awarię.</para>
<para>Przykłady rozwiązywania problemów raportowanych przez ZFS w <olink remap="external" targetdoc="chapter-9.xml" targetptr="gbbvb">Naprawa brakującego urządzenia</olink>.</para>
</sect2>
<sect2 xml:id="gcfiw">
<title>Nowe polecenie <command>zpool clear</command></title>
<para>
<emphasis role="strong">Solaris Express 4/06:</emphasis> Wydanie to zawiera komendę <command>zpool clear</command>, służącą do zerownia licznika błędów związanych z urządzeniem lub pulą. Poprzednio licznik błędów był zerowany, kiedy urządzenie w puli było włączane ponownie za pomocą polecenia <command>zpool online</command>.
Więcej informacji w <olink remap="external" targetdoc="819-2240" targetptr="zpool-1m">
<citerefentry>
<refentrytitle>zpool</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink> oraz <olink remap="external" targetdoc="chapter-4.xml" targetptr="gazge">Czyszczenie urządzeń puli nośników danych</olink>.</para>
</sect2>
<sect2 xml:id="gcajn">
<title>Skrócony format ACL-i NFSv4</title>
<para>
<emphasis role="strong">Solaris Express 4/06:</emphasis> W wydaniu tym są dostępne trzy formaty ACLI- NFSv4: informacyjny (verbose), pozycyjny i skrócony. Nowe formaty ACL: skrócony i pozycyjny są dostępne, aby ustawiać i wyświetlać ACL-e. Możesz używać polecenia <command>chmod</command>, aby ustawić wszystkie 3 formaty ACL-i. Możesz używać polecenia <command>ls</command> <option>V</option>, aby wyświetlić skrócony i pozycyjny format ACL-i oraz polecenia <command>ls</command> <option> v</option>, aby wyświetlić format informacyjny (verbose) ACL-i.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-7.xml" targetptr="gbchf">Ustawianie i drukowanie ACL-i dla plików ZFs-a w formacie skróconym</olink>, <olink remap="external" targetdoc="819-2239" targetptr="chmod-1">
<citerefentry>
<refentrytitle>chmod</refentrytitle>
<manvolnum>
1
</manvolnum>
</citerefentry>
</olink> oraz <olink remap="external" targetdoc="819-2239" targetptr="ls-1">
<citerefentry>
<refentrytitle>ls</refentrytitle>
<manvolnum>
1
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gcakl">
<title>Narzędzie Monitorowania Systemu Plików (File System Monitoring Tool) (<command>fsstat</command>)</title>
<para>
<emphasis role="strong">Solaris Express 4/06:</emphasis> Nowe narzędzie do monitorowania systemu plików, <command>fsstat</command>, jest dostępne do raportowania operacji na systemie plików. Aktywność może być raportowana według punktu montowania systemu plików bądź według jego typu. Poniższy przykład przedstawia ogólne statystyki aktywności systemu plików ZFS.</para>
<screen>$ <userinput>fsstat zfs</userinput>
 new  name   name  attr  attr lookup rddir  read read  write write
 file remov  chng   get   set    ops   ops   ops bytes   ops bytes
7.82M 5.92M 2.76M 1.02G 3.32M  5.60G 87.0M  363M 1.86T 20.9M  251G zfs</screen>
<para>Więcej informacji w <olink remap="external" targetdoc="819-2240" targetptr="fsstat-1m">
<citerefentry>
<refentrytitle>fsstat</refentrytitle>
<manvolnum>
1M
</manvolnum>
</citerefentry>
</olink>.</para>
</sect2>
<sect2 xml:id="gbsbp">
<title>Zarządzanie ZFS-em przez interfejs WWW</title>
<para>
<emphasis role="strong">Solaris Express 1/06:</emphasis> Zostało udostępnione narzędzie administracyjne ZFS zbudowane w oparciu o interfejs web. Za pomocą tego narzędzia można wykonywać następujące czynności:</para>
<itemizedlist>
<listitem>
<para>Tworzenie nowej puli nośników danych.</para>
</listitem>
<listitem>
<para>Dodawanie przestrzeni dla danych do istniejącej puli.</para>
</listitem>
<listitem>
<para>Przenoszenie (eksport) puli nośników danych do innego systemu.</para>
</listitem>
<listitem>
<para>Import uprzednio eksportowanych pul nośników danych celem udostępnienia ich w innym systemie.</para>
</listitem>
<listitem>
<para>Podgląd informacji o puli nośników danych.</para>
</listitem>
<listitem>
<para>Tworzenie systemu plików.</para>
</listitem>
<listitem>
<para>Tworzenie woluminu.</para>
</listitem>
<listitem>
<para>Tworzenie obrazu systemu plików lub woluminu.</para>
</listitem>
<listitem>
<para>Przywracanie systemu plików do poprzedniego obrazu.</para>
</listitem>
</itemizedlist>
<para>Dostęp do konsoli Administracji ZFS możliwe jest przez bezpieczne połączenie przy pomocy przeglądarki web pod następującym adresem URL:</para>
<screen>https://<replaceable>system-name</replaceable>:6789/zfs</screen>
<para>Jeśli po wpisaniu poprawengo adresu URL nie pojawia się konsola administracyjna, oznacza to najprawdopodobniej, że serwer jest nieuruchomiony. Włącza się go następującym poleceniem:</para>
<screen># /usr/sbin/smcwebserver start</screen>
<para>Automatyczne uruchamianie serwera podczas startu systemu włączane jest następującą komendą:</para>
<screen># /usr/sbin/smcwebserver enable</screen>
<note>

<para>Nie można użyć Konsoli Zarządzania Solarisem (<command>smc</command>)
do zarządzania pulami ZFS lub systemami plików.</para>
</note>
<para>Nie można zarządzać systemami plików ZFS zdalnie przy użyciu konsoli administracji
ZFS-em, ponieważ w ostatnich wydaniach Solaris Express wyłączono część serwisów sieciowych
automatycznie. Należy użyć następującego polecenia w celu włączenia tych serwisów:</para>
<screen># <userinput>netservices open</userinput>
</screen>
</sect2>
</sect1>
<sect1 xml:id="zfsover-2">
<title>Czym jest ZFS?</title>
<para>Solarisowy system plików ZFS jest rewolucyjnym, nowym systemem plików, który zmienia sposób administracji systemem plików oraz którego funkcjonalność oraz korzyści z niej płynące są niespotykane dzisiaj w żadnym innym systemie plików. ZFS został zaprojektowany by być mocnym, skalowalnym oraz prostym w administracji.<indexterm xml:id="indexterm-1">
<primary>System plików ZFS</primary>
<secondary>opis</secondary></indexterm>
</para>
<sect2 xml:id="gaypk">
<title>Pula danych ZFS</title>
<para>ZFS używa koncepcji <emphasis>pul nośników danych</emphasis>, aby zarządzać urządzeniami fizycznymi. Uprzednio systemy plików były konstruowane na pojedynczych, fizycznych urządzeniach. Aby zaadresować wiele urządzeń oraz zapewnić redundancję została przedstawiona koncepcja <emphasis>managera woluminów</emphasis>, prezentującego obraz pojedynczego urządzenia, który nie musiał być modyfikowany, aby korzystać z zalet wykorzystania kilku urządzeń. Taki schemat stworzył dodatkowy poziom i ostatecznie uniemożliwił wykorzystanie pewnych zalet systemu plików, ponieważ system plików nie miał kontroli nad fizyczną lokalizacją danych w wirtualnych woluminach.<indexterm xml:id="indexterm-2">
<primary>System plików ZFS</primary>
<secondary>pula nośników danych</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-3">
<primary>pula nośników danych</primary>
<secondary>opis</secondary>
</indexterm>
</para>
<para>ZFS eliminuje całkowicie managera woluminów. Zamiast zmuszać do tworzenia wirtualnych woluminów, ZFS grupuje urządzenia w pule nośników danych. Pula nośników danych opisuje fizyczną charakterystykę zbioru danych (podział logiczny urządzenia, sposób redundancji danych, itd.) i działa jako magazyn danych, z którego systemy plików mogą być tworzone. System plików nie zawiera już indywidualnych urządzeń, co pozwala im na dzielenie się przestrzenią dyskową ze wszystkimi systemami plików w puli. Nie trzeba już dłużej z góry definiować wielkości systemu plików, rośnie on automatycznie w przestrzeni dyskowej, jaką zadedykowano na potrzeby puli. W momencie gdy zostają dodane nowe urządzenia, wszystkie systemy plików potrafią używać dodatkowej przestrzeni, bez potrzeby ingerencji. W pewien sposób pule nośników danych zachowują się podobnie do systemu pamięć wirtualnej. Kiedy dodawane są pamięci DIMM do systemu, system operacyjny nie wymusza wykonania jakichkolwiek poleceń, aby skonfigurować pamięć, by przypisać ją do indywidualnego procesu. Wszystkie procesy w systemie automatycznie wykorzystują dodatkową pamięć.</para>
</sect2>
<sect2 xml:id="gaypi">
<title>Terminologia transakcyjna</title>
<para>ZFS jest transakcyjnym systemem plików, co znaczy że stan systemu plików na dysku jest zawsze spójny. Tradycyjny system plików nadpisuje dane, co oznacza iż jeśli zdarzy się utrata zasilania, przykładowo, pomiędzy czasem kiedy blok danych zostanie zaalokowany a kiedy zostanie połącstrefy wewnątrz katalogu, system plików pozostanie w stanie nieustalonym (niespójnym). Wcześniej problem ten był rozwiązywany poprzez użycie polecenia <command>fsck</command>. Było ono odpowiedzialne za przeczytanie i zweryfikowanie stanu systemu plików oraz wykonanie prób naprawy każdej napotkanej niespójności. Problem ten było dokuczliwy i nigdy nie gwarantował rozwiązania wszystkich problemów. Dopiero niedawno przedstawiono koncepcję <emphasis>indeksowania</emphasis> (journaling). Polega ona na zapisywaniu wszystkich działań w oddzielnym indeksie, który może być odtworstrefy bezpiecznie, jeśli system ulegnie awarii. Taki proces tworzy niepotrzebną nadmiarowość, ponieważ dane muszą być zapisywane podwójnie, a czasem wynikiem są dodatkowe problemy, takie jak wtedy, gdy indeksowania nie mogą być odtworzone poprawnie.<indexterm xml:id="indexterm-4">
<primary>System plików ZFS</primary>
<secondary>terminologia transakcyjna</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-5">
<primary>terminologia transakcyjna</primary>
<secondary>opis</secondary>
</indexterm>
</para>
<para>W transakcyjnym systemie plików, dane zarządzane są sposobem <emphasis>copy on write</emphasis>. Dane nie są nigdy nadpisywane, a żadna z sekwencji operacji nie jest zarówno nigdy całkowicie zatwierdzana, ani całkowicie ignorowana. Mechanizm ten oznacza, iż system plików nigdy nie zostanie popsuty poprzez przypadkowy zanik zasilania lub awarię systemu. Zatem nie ma potrzeby, by istniał odpowiednik polecenia <command>fsck</command>. Kiedy ostatnio zapisywane części danych mogły zostać utracone, system plików zawsze pozostaje spójnym. Ponadto zsynchronizowane dane (zapisywane z flagą <varname>O_DSYNC</varname>), są zawsze zapisywane zanim zostaną zwrócone, dlatego istnieje gwarancja iż nie ma możliwości ich utraty.</para>
</sect2>
<sect2 xml:id="gaypb">
<title>Sumy kontrolne i samonaprawa danych </title>
<para>W ZFS-ie, z wszystkich danych zlicza się sumy kontrolne przy wykorzystanie algorytmu wybranego przez użytkownika. Tradycyjne systemy plików pozwalały na przeprowadzanie sum kontrolnych na poziomie bloków danych, poza poziomem managera woluminów i tradycyjnego systemu plików. Ten tradycyjny schemat oznacza, że pewne rodzaje błędów, takie jak zapis całego bloku do nieprawidłowej lokacji, może skutkować poprawną sumą kontrolną w rzeczywistości niepoprawnych danych. Sumy kontrolne ZFS są przechowywane w taki sposób, iż takiego rodzaju awarie są wykrywane i mogą być odzyskane bez problemów. Całe obliczanie sum kontrolnych i odzyskiwanie danych, wykonywane jest na warstwie systemu plików i jest nie widoczna dla aplikacji.<indexterm xml:id="indexterm-6">
<primary>System plików ZFS</primary>
<secondary>checksummed data</secondary>
<tertiary>description</tertiary>
</indexterm>
<indexterm xml:id="indexterm-7">
<primary>checksummed data</primary>
<secondary>description</secondary>
</indexterm>
</para>
<para>Dodatkowo, ZFS posiada zdolność samodzielnej naprawy danych. ZFS wspiera pule nośników danych wraz z różnymi poziomami redundancji danych, włączając w to mirroring i wariacje RAID-5. Gdy zostanie wykryty zły blok danych, ZFS importuje poprawne dane z innej kopii, naprawia złe dane, zamieniając je na dobrą kopię.</para>
</sect2>
<sect2 xml:id="gayou">
<title>Niezrównana skalowalność</title>

<para>ZFS został zaprojektowany od podstaw, aby być najbardziej skalowalnym systemem plików. System sam w sobie jest 128-bitowy, pozwalając na 2<superscript>128</superscript> bajtów danych. Wszystkie dane są alokowane dynamicznie, zatem nie ma potrzeby wcześniejszego alokowania danych, innymi słowy ograniczenia skalowalności systemu plików, kiedy jest on tworstrefy na początku. Całość algorytmów została napisana z myślą o skalowalności. Katalogi mogą zawierać do 2<superscript>48</superscript> (256 trylionów) wpisów oraz nie ma limitu dla ilości systemów plików jak i ilości plików jakie może on zawierać.</para>
</sect2>
<sect2 xml:id="gbcbn">
<title>Obrazy ZFS</title>

<para><emphasis>Obraz</emphasis> jest kopią tylko do odczytu systemu plików lub woluminu. Obrazy mogą być tworzone szybko i łatwo. Początkowo obraz nie zajmuje dodatkowej przestrzeni dyskowej wewnątrz puli.</para>
<para>W trakcie gdy dane wewnątrz aktywnego dataset'u ulegają zmianom, obraz zaczyna zajmować miejsce jako kontynuacja referencji do starych danych. Jako rezultat tego, obraz zapobiega uwolnieniu danych z powrotem do puli.</para>
</sect2>
<sect2 xml:id="gayoc">
<title>Uproszczona Administracja</title>

<para>Co najważniejsze, ZFS posiada znacznie uproszcstrefy model administrowania. Poprzez użycie hierarchicznego wyglądu systemu plików, dziedziczenie właściwości, samozarządzalność punktów montowania i semantykę udostępniania NFS, ZFS umożliwia tworzenie i zarządzanie systemem plików bez bez potrzeby stosowania wielu poleceń lub edytowań plików konfiguracyjnych. Możesz łatwo ustawić quota'y lub rezerwacje, włączyć / wyłączyć kompresję lub zarządzać punktami montowań dla kilku systemu plików za pomocą jednego polecenia. Urządzenia mogą być przetestowane lub naprawione bez potrzeby znajomości oddzielnego zestawu poleceń dla managera woluminów. Możliwym jest też stworzenie nieograniczonej ilości obrazów systemu plików w trybie natychmiastowym. Można tworzyć kopie zapasowe i odtwarzać dane indywidualnych systemów plików.<indexterm xml:id="indexterm-8">
<primary>System plików ZFS</primary>
<secondary>uproszczona administracja</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-9">
<primary>uproszczona administracja</primary>
<secondary>opis</secondary>
</indexterm>
</para>
<para>ZFS zarządza systemem plików poprzez hierarchię dlatego umożliwia to uproszczenie zarządzania właściwościami takimi jak quota'y, rezerwacje, kompresja i punkty montowań. W tym modelu, system plików staje się centralnym punktem kontrolnym. Sam system plików staje się tani (w porównaniu do nowego katalogu), zatem zachęcającym jest tworzenie systemu plików dla każdego użytkownika, projektu, obszaru działania, itd. Ten model pozwala na definiowanie dopasowanych punktów zarządzania.</para>
</sect2>
</sect1>
<sect1 xml:id="ftyue">
<title>Terminologia ZFS</title>
<para>Ta sekcja opisuje podstawową terminologię wykorzystaną w tej książce:</para>
<variablelist>
<varlistentry>
<term>suma kontrolna</term>
<listitem>
<para>256-bitowe mieszanie danych w blokach systemu plików. Suma kontrolna może zawierać się w zakresie od prostego i szybkiego fletcher2 (domyślnie) do kryptograficznie mocnego mieszania jak SHA256.<indexterm xml:id="indexterm-10">
<primary>System plików ZFS</primary>
<secondary>suma kontrolna</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-11">
<primary>suma kontrolna</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-12">
<primary>terminologia</primary>
<secondary>suma kontrolna</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>klon</term>
<listitem>
<para>Jest to system plików, którego zawartość początkowa jest identyczna z zawartością obrazu.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbcxz">Wprowadzenie do klonów ZFS</olink>.<indexterm xml:id="indexterm-13">
<primary>System plików ZFS</primary>
<secondary>klony</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-14">
<primary>klon</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-15">
<primary>terminologia</primary>
<secondary>klony</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>dataset</term>
<listitem>
<para>Ogólna nazwa dla następujących elementów ZFS: klony, systemy plików, obrazy lub woluminy.</para>
<para>Każdy dataset jest identyfikowany poprzez unikalną nazwę w przestrzeni nazw ZFS. Datasety są identyfikowane przez użycie następującego formatu:</para>
<para>
<replaceable>pula</replaceable>/<replaceable>ścieżka</replaceable>[<replaceable>@obraz</replaceable>]</para>
<variablelist>
<varlistentry>
<term>
<replaceable>pula</replaceable>
</term>
<listitem>
<para>Identyfikuje nazwę puli nośników danych, która zawiera dataset</para>
</listitem>
</varlistentry>
<varlistentry>
<term>
<replaceable>ścieżka</replaceable>
</term>
<listitem>
<para>Jest to separowana ukośnikiem nazwa ścieżki do obiektu dataset</para>
</listitem>
</varlistentry>
<varlistentry>
<term>
<replaceable>obraz</replaceable>
</term>
<listitem>
<para>Jest komponentem opcjonalnym, który identyfikuje obraz datasetu</para>
</listitem>
</varlistentry>
</variablelist>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gavwq">Rozdział 5, Zarządzanie systemem plików ZFS</olink>.<indexterm xml:id="indexterm-16">
<primary>System plików ZFS</primary>
<secondary>dataset</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-17">
<primary>dataset</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-18">
<primary>terminologia</primary>
<secondary>dataset</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>system plików</term>
<listitem>
<para>Dataset, który zawiera standardowy system plików POSIX.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-5.xml" targetptr="gavwq">Rozdział 5, Zarządzanie systemem plików ZFS</olink>.<indexterm xml:id="indexterm-19">
<primary>System plików ZFS</primary>
<secondary>system plików</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-20">
<primary>system plików</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-21">
<primary>terminologia</primary>
<secondary>system plików</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>mirror</term>
<listitem>
<para>Urządzenie wirtualne, która przechowuje identyczne kopie danych na dwóch lub więcej, dyskach. Jeśli którykolwiek z dysków w konfiguracji mirror`a popsuje się, inny dysk może udostępniając te same dane.<indexterm xml:id="indexterm-22">
<primary>Pule nośników danych ZFS</primary>
<secondary>mirror</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-23">
<primary>mirror</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-24">
<primary>terminologia</primary>
<secondary>mirror</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>pula</term>
<listitem>
<para>Logiczna grupa urządzeń opisujących wygląd i charakterystyki fizyczne dostępnych nośników danych. Przestrzeń dla datasetów jest poświęcana z puli.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gavwn">Rozdział 4, Zarządzanie pulami nośników danych ZFS</olink>.<indexterm xml:id="indexterm-25">
<primary>pule nośników danych ZFS</primary>
<secondary>pula</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-26">
<primary>pula</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-27">
<primary>terminologia</primary>
<secondary>pula</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>RAID-Z</term>
<listitem>
<para>Wirtualne urządzenie, które przechowuje dane i dane parzystości na wielu dyskach, zbliżone do RAID-5. <indexterm xml:id="indexterm-28">
<primary>pule nośników danych ZFS</primary>
<secondary>RAID-Z</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-29">
<primary>RAID-Z</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-30">
<primary>terminologia</primary>
<secondary>RAID-Z</secondary>
</indexterm>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gamtu">Konfiguracja puli nośników danych RAID-Z</olink>.</para>
</listitem>
</varlistentry>
<varlistentry>
<term>resilvering</term>
<listitem>
<para>Proces transferu danych z jednego urządzenia na drugie jest znany jako <emphasis>resilvering</emphasis>. Przykładowo, jeśli mirror zostanie wymieniony lub zostanie wyłączony ze strefy, dane z mirrora który jest aktualny są kopiowane do nowo przywróconego komponentu mirroru. Ten proces odpowiada <emphasis>resynchronizacji mirrora</emphasis> w tradycyjnym managerze woluminów.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-9.xml" targetptr="gbcus">Podgląd postępu resilveringu</olink>.<indexterm xml:id="indexterm-31">
<primary>pule nośników danych ZFS</primary>
<secondary>resilvering</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-32">
<primary>resilvering</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-33">
<primary>terminologia</primary>
<secondary>resilvering</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>obraz</term>
<listitem>
<para>Obraz systemu plików lub woluminu tylko do odczytu z danego punktu czasowego.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-6.xml" targetptr="gbciq">Wprowadzenie do obrazów ZFS</olink>.<indexterm xml:id="indexterm-34">
<primary>System plików ZFS</primary>
<secondary>obraz</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-35">
<primary>snapshot</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-36">
<primary>terminologia</primary>
<secondary>obraz</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>urządzenie wirtualne</term>
<listitem>
<para>Logiczne urządzenie w puli, które może być fizycznym urządzeniem, plikiem lub zbiorem urzadzeń.</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-4.xml" targetptr="gazca">Rozpoznawanie wirtualnych urządzeń w pulach nośników danych</olink>.<indexterm xml:id="indexterm-37">
<primary>pule nośników danych ZFS</primary>
<secondary>urządzenie wirtualne</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-38">
<primary>urządzenie wirtualne</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-39">
<primary>terminologia</primary>
<secondary>urządzenie wirtualne</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>wolumin</term>
<listitem>
<para>Dataset użyty w celu emulacji fizycznego urządzenia. Na przykład można użyć emulowanego woluminu w celu stworzenia urządzenia wymiany danych (swap device).</para>
<para>Więcej informacji w <olink remap="external" targetdoc="chapter-8.xml" targetptr="gaypf">Woluminy ZFS</olink>.<indexterm xml:id="indexterm-40">
<primary>System plików ZFS</primary>
<secondary>wolumin</secondary>
<tertiary>definicja</tertiary>
</indexterm>
<indexterm xml:id="indexterm-41">
<primary>wolumin</primary>
<secondary>definicja</secondary>
</indexterm>
<indexterm xml:id="indexterm-42">
<primary>terminologia</primary>
<secondary>wolumin</secondary>
</indexterm>
</para>
</listitem>
</varlistentry>
</variablelist>
</sect1>
<sect1 xml:id="gbcpt">
<title>Wymagania nazewnictwa komponentów ZFS</title>
<para>Każdy komponent ZFS musi posiadać nazwę zgodną z następującymi zasadami:<indexterm xml:id="indexterm-43">
<primary>System plików ZFS</primary>
<secondary>wymagania nazewnictwa komponentów</secondary>
</indexterm>
<indexterm xml:id="indexterm-44">
<primary>komponenty ZFS</primary>
<secondary>wymagania nazewnictwa</secondary>
</indexterm>
<indexterm xml:id="indexterm-45">
<primary>wymagania nazewnictwa</primary>
<secondary>komponenty ZFS</secondary>
</indexterm>
</para>
<itemizedlist>
<listitem>
<para>Puste komponenty są niedozwolone.</para>
</listitem>
<listitem>
<para>Każdy komponent może zawierać tylko alfanumeryczne znaki, dodatkowo cztery następujące znaki:</para>
<itemizedlist>
<listitem>
<para>Podkreślnik (_)</para>
</listitem>
<listitem>
<para>Pauza (-)</para>
</listitem>
<listitem>
<para>Dwukropek (:)</para>
</listitem>
<listitem>
<para>Kropka (.)</para>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<para>Nazwy puli muszą zaczynać się literą, z wyjątkiem sekwencji c[0-9], która jest niedozwolona. Także nazwy puli zaczynające się <literal>mirror</literal>, <literal>raidz</literal> lub <literal>spare</literal> są niedozwolone, gdyż te nazwy są już zajęte.</para>
</listitem>
<listitem>
<para>Nazwy datasetów muszą zaczynać się znakiem alfanumerycznym.</para>
</listitem>
</itemizedlist>
</sect1>
</chapter>
