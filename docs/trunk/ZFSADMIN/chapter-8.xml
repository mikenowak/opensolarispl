<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML//EN" "docbook.dtd"[
	<!ENTITY % xinclude SYSTEM "xinclude.mod">
	%xinclude;
]>

<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="ftyxh">



<title>ZFS - zagadnienia zaawansowane</title>
<toc>
<para>W tym rozdziale przedstawiono emulowane woluminy, używanie ZFS-a w systemie Solaris
z zainstalowanymi zonami, ZFS-owe alternatywne pule główne oraz ZFS-owe profile praw.</para>
<para>Rozdział składa się z następujących podrozdziałów:</para>
<itemizedlist>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gaypf">Emulowane woluminy</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gayov">Używanie ZFS-a w systemie Solaris z zainstalowanymi zonami</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gbcgl">ZFS-owe alternatywne pule główne</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gbfvq">ZFS-owe profile praw</olink>
</para>
</listitem>
</itemizedlist>
</toc>
<sect1 xml:id="gaypf">
<title>Emulowane woluminy</title>
<para><emphasis>Emulowany wolumin</emphasis> to zbiór danych (dataset) reprezentujący
urządzenie blokowe, którego można używać jak każdego innego urządzenia blokowego.  Woluminom tym odpowiadają
pliki urządzeń w katalogu <filename>/dev/zvol/{dsk,rdsk}/path</filename>.<indexterm xml:id="indexterm-461">
<primary>emulowany wolumin</primary>
<secondary>opis</secondary>
</indexterm>
<indexterm xml:id="indexterm-462">
<primary>tworzenie</primary>
<secondary>emulowanego woluminu</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-463">
<primary>systemy plików ZFS</primary>
<secondary>tworzenie emulowanego woluminu</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>Poniższy przykład ilustruje tworzenie ZFS-owego woluminu <filename>tank/vol</filename> o pojemności 5 GB:</para>
<screen># <userinput>zfs create -V 5gb tank/vol</userinput>
</screen>
<para>Podczas tworzenia woluminu, rezerwacja jest automatycznie ustawiana
na rozmiar równy początkowej wielkości woluminu.  Wielkość rezerwacji cały
czas jest równa wielkości woluminu, dzięki czemu nie występują nieprzewidziane
efekty.  Na przykład, jeśli wielkość woluminu zmniejsza się, może
nastąpić uszkodzenie danych.  Należy zachować ostrożność podczas zmniejszania
woluminu.</para>
<para>Jeśli używasz systemu Solaris z zainstalowanymi zonami, nie możesz tworzyć ani klonować ZFS-owego woluminu
w zonie innej niz globalna.  Jakakolwiek próba stworzenia lub sklonowania 
woluminu z zony innej niż globalna nie powiedzie się.  Więcej
informacji o używaniu ZFS-owych woluminów w globalnej zonie w
<olink targetdoc="" remap="internal" targetptr="gbebi">Dodawanie ZFS-owych woluminów do zon innych niz globalna</olink>.</para>
<sect2 xml:id="gbfvg">
<title>Emulowane woluminy jako urządzenia wymiany (swap) i urządzenia zrzutów awaryjnych</title>
<para>W celu skonfigurowania przestrzeni wymiany należy utworzyć ZFS-owy wolumin o ustalonym rozmiarze
i włączyć wymianę na to urządzenie. Nie należy używać jako urządzenia wymiany pliku w ZFS-owym systemie
plików. Konfiguracja z ZFS-owym plikiem wymiany nie jest obsługiwana.<indexterm xml:id="indexterm-464">
<primary>emulowany wolumin</primary>
<secondary>jako urządzenie wymiany</secondary>
</indexterm>
<indexterm xml:id="indexterm-465">
<primary>tworzenie</primary>
<secondary>emulowanego woluminu jako urządzenia wymiany</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-466">
<primary>ZFS-owe systemy plików</primary>
<secondary>tworzenie emulowanego woluminu jako urządzenia wymiany</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>Poniższy przykład ilustruje dodanie woluminu <filename>tank/vol</filename> wielkości 5 GB
jako urządzenia wymiany.</para>
<screen># <userinput>swap -a /dev/zvol/dsk/tank/vol</userinput>
# <userinput>swap -l</userinput>
swapfile                 dev  swaplo blocks   free
/dev/dsk/c0t0d0s1      32,33      16 1048688  1048688
/dev/zvol/dsk/tank/vol 254,1      16 10485744 10485744</screen>
<para>Używanie woluminu ZFS-a jako urządzenia zrzutów awaryjnych nie jest obsługiwane. W celu
skonfigurowania urządzenia zrzutów awaryjnych należy użyć komendy <command>dumpadm</command>.</para>
</sect2>
</sect1>
<sect1 xml:id="gayov">
<title>Używanie ZFS-a w systemie Solaris z zainstalowanymi zonami</title>
<para>Datasety ZFS-a można dodać do zony jako ogólny system plików lub jako wydelegowany dataset.</para>
<para>Dodanie systemu plików umożliwia nieglobalnej zonie współdzielenie przestrzeni z zoną globalną, aczkolwiek administrator zony nie może kontrolować właściwości lub tworzyć nowych systemów plików w hierarchii. Mechanizm ten działa identycznie jak podłączenie do zony dowolnego innego systemu pliów i powinien być wykorzystywany głównie do współdzielenia miejsca.</para>
<para>ZFS also allows datasets to be delegated to a non-global zone, giving
complete control over the dataset and all its children to the zone administrator.
The zone administrator can create and destroy file systems within that dataset,
and modify properties of the datasets. The zone administrator cannot affect
datasets that have not been added to the zone, and cannot exceed any top-level
quotas set on the exported dataset.<indexterm xml:id="indexterm-467">
<primary>zones</primary>
<secondary>using with ZFS file systems</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-468">
<primary>systemy plików ZFS</primary>
<secondary>using on a Solaris system with zones installed</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<para>Consider
the following interactions when working with ZFS on a system with Solaris
zones installed:</para>
<itemizedlist>
<listitem>
<para>A ZFS file system that is added to a non-global zone must
have its <command>mountpoint</command> property set to legacy.</para>
</listitem>
<listitem>
<para>When a source <literal>zonepath</literal> and the
target <literal>zonepath</literal> both reside on ZFS and are in the same
pool, <command>zoneadm clone</command> will now automatically use ZFS clone
to clone a zone. The <command>zoneadm clone</command> command will take a
ZFS snapshot of the source <literal>zonepath</literal> and set
up the target <literal>zonepath</literal>. Do not use the ZFS snapshot features
to clone a zone. For more information, see <olink targetdoc="819-2450" remap="external" targetptr="zone">Part II, <citetitle remap="chapter">Zones,</citetitle> in <citetitle remap="book">System Administration Guide: Solaris Containers-Resource Management
and Solaris Zones</citetitle>
</olink>.</para>
</listitem>
</itemizedlist>
<sect2 xml:id="gbbrq">
<title>Adding ZFS File Systems to a Non-Global Zone</title>
<para>You can add a ZFS file system as a generic file system when the goal
is solely to share space with the global zone. A ZFS file system that is added
to a non-global zone must have its <literal>mountpoint</literal> property
set to legacy.</para>
<para>You can add a ZFS file system to a non-global zone by using the <command>zonecfg</command> command's <literal>add fs</literal> subcommand. For example:<indexterm xml:id="indexterm-469">
<primary>zones</primary>
<secondary>adding ZFS file system to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-470">
<primary>adding</primary>
<secondary>ZFS file system to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-471">
<primary>systemy plików ZFS</primary>
<secondary>adding ZFS file system to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a ZFS file system is added to a non-global
zone by a global administrator in the global zone.</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add fs</userinput>
zonecfg:zion:fs&gt; <userinput>set type=zfs</userinput>
zonecfg:zion:fs&gt; <userinput>set special=tank/zone/zion</userinput>
zonecfg:zion:fs&gt; <userinput>set dir=/export/shared</userinput>
zonecfg:zion:fs&gt; <userinput>end</userinput>
</screen>
<para>This syntax adds the ZFS file system, <filename>tank/zone/zion</filename>,
to the zone <literal>zion</literal>, mounted at <filename>/export/shared</filename>.
The <property>mountpoint</property> property of the file system must be set
to <property>legacy</property>, and the file system cannot already be mounted
in another location. The zone administrator can create and destroy files within
the file system. The file system cannot be remounted in a different location,
nor can the zone administrator change properties on the file system such as
atime, readonly, compression, and so on.  The
global zone administrator is responsible for setting and controlling properties
of the file system.</para>
<para>For more information about the <command>zonecfg</command> command and
about configuring resource types with <command>zonecfg</command>, see <olink targetdoc="819-2450" remap="external" targetptr="zone">Part II, <citetitle remap="chapter">Zones,</citetitle> in <citetitle remap="book">System Administration Guide: Solaris
Containers-Resource Management and Solaris Zones</citetitle>
</olink>.</para>
</sect2>
<sect2 xml:id="gbbst">
<title>Delegating Datasets to a Non-Global Zone</title>
<para>If the primary goal is to delegate the administration of storage to
a zone, then ZFS supports adding datasets to a non-global zone through use
of the <command>zonecfg</command> command's <literal>add dataset</literal> subcommand.<indexterm xml:id="indexterm-472">
<primary>zones</primary>
<secondary>delegating dataset to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-473">
<primary>delegating</primary>
<secondary>dataset to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-474">
<primary>systemy plików ZFS</primary>
<secondary>delegating dataset to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a ZFS file system is delegated to a non-global
zone by a global administrator in the global zone.</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add dataset</userinput>
zonecfg:zion:dataset&gt; <userinput>set name=tank/zone/zion</userinput>
zonecfg:zion:dataset&gt; <userinput>end</userinput>
</screen>
<para>Unlike adding a file system, this syntax causes the ZFS file system <filename>tank/zone/zion</filename> to be visible within the zone <literal>zion</literal>.
The zone administrator can set file system properties, as well as create children.
In addition, the zone administrator can take snapshots, create clones, and
otherwise control the entire file system hierarchy.</para>
<para>For more information about what actions are allowed within zones, see <olink targetdoc="" remap="internal" targetptr="gbbsn">Property Management Within a Zone</olink>.</para>
</sect2>
<sect2 xml:id="gbebi">
<title>Adding ZFS Volumes to a Non-Global Zone</title>
<para>Emulated volumes cannot be added to a non-global zone by using the <command>zonecfg</command> command's <literal>add dataset</literal> subcommand. If
an attempt to add an emulated volume is detected, the zone cannot boot. However,
volumes can be added to a zone by using the <command>zonecfg</command> command's <literal>add device</literal> subcommand.<indexterm xml:id="indexterm-475">
<primary>zones</primary>
<secondary>adding ZFS volume to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-476">
<primary>adding</primary>
<secondary>ZFS volume to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-477">
<primary>systemy plików ZFS</primary>
<secondary>adding ZFS volume to a non-global zone</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a ZFS emulated volume is added to a non-global
zone by a global administrator in the global zone:</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add device</userinput>
zonecfg:zion:device&gt; <userinput>set match=/dev/zvol/dsk/tank/vol</userinput>
zonecfg:zion:device&gt; <userinput>end</userinput>
</screen>
<para>This syntax exports the <literal>tank/vol</literal> emulated volume
to the zone. Note that adding a raw volume to a zone has implicit security
risks, even if the volume doesn't correspond to a physical device. In particular,
the zone administrator could create malformed file systems that would panic
the system when a mount is attempted. For more information about adding devices
to zones and the related security risks, see <olink targetdoc="" remap="internal" targetptr="gbbre">Understanding the <property>zoned</property> Property</olink>.</para>
<para>For more information about adding devices to zones, see <olink targetdoc="819-2450" remap="external" targetptr="zone">Part II, <citetitle remap="chapter">Zones,</citetitle> in <citetitle remap="book">System Administration Guide: Solaris
Containers-Resource Management and Solaris Zones</citetitle>
</olink>.</para>
</sect2>
<sect2 xml:id="gbbso">
<title>Using ZFS Storage Pools Within a Zone</title>
<para>ZFS storage pools cannot be created or modified within a zone. The delegated
administration model centralizes control of physical storage devices within
the global zone and control of virtual storage to non-global zones. While
a pool-level dataset can be added to a zone, any command that modifies the
physical characteristics of the pool, such as creating, adding, or removing
devices, is not allowed from within a zone. Even if physical devices are added
to a zone by using the <command>zonecfg</command> command's <literal>add device</literal> subcommand,
or if files are used, the <command>zpool</command> command does not allow
the creation of any new pools within the zone.</para>
</sect2>
<sect2 xml:id="gbbsn">
<title>Property Management Within a Zone</title>
<para>Once a dataset is added to a zone, the zone administrator can control
specific dataset properties. When a dataset is added to a zone, all its ancestors
are visible as read-only datasets, while the dataset itself is writable as
are all its children. For example, consider the following configuration:<indexterm xml:id="indexterm-478">
<primary>zones</primary>
<secondary>ZFS property management within a zone</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-479">
<primary>ZFS properties</primary>
<secondary>management within a zone</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-480">
<primary>systemy plików ZFS</primary>
<secondary>property management within a zone</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<screen>global# <userinput>zfs list -Ho name</userinput>
tank
tank/home
tank/data
tank/data/matrix
tank/data/zion
tank/data/zion/home</screen>
<para>If <filename>tank/data/zion</filename> is added to a zone, each dataset
would have the following properties.</para>
<informaltable frame="topbot">
<tgroup cols="4" colsep="0" rowsep="0">
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<thead>
<row rowsep="1">
<entry>
<para>Dataset</para>
</entry>
<entry>
<para>Visible</para>
</entry>
<entry>
<para>Writable</para>
</entry>
<entry>
<para>Immutable Properties</para>
</entry>
</row>
</thead>
<tbody>
<row>
<entry>
<para>
<filename>tank</filename>
</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/home</filename>
</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>-</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data</filename>
</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/matrix</filename>
</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>-</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/zion</filename>
</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>
<property>sharenfs</property>, <property>zoned</property>, <property>quota</property>, <property>reservation</property>
</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/zion/home</filename>
</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>
<property>sharenfs</property>, <property>zoned</property>
</para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<para>Note that every parent of <filename>tank/zone/zion</filename> is visible
read-only, all children are writable, and datasets that are not part of the
parent hierarchy are not visible at all. The zone administrator cannot change
the <property>sharenfs</property> property, because non-global zones cannot
act as NFS servers. Neither can the zone administrator change the <literal>zoned</literal> property,
because doing so would expose a security risk as described in the next section. </para>
<para>Any other property can be changed, except for the added dataset itself,
where the <property>quota</property> and <property>reservation</property> properties
cannot be changed. This behavior allows the global zone administrator to control
the space consumption of all datasets used by the non-global zone.</para>
<para>In addition, the <property>sharenfs</property> and <property>mountpoint</property> properties
cannot be changed by the global zone administrator once a dataset has been
added to a non-global zone.</para>
</sect2>
<sect2 xml:id="gbbre">
<title>Understanding the <property>zoned</property> Property</title>
<para>When a dataset is added to a non-global zone, the dataset must be specially
marked so that certain properties are not interpreted within the context of
the global zone. Once a dataset has been added to a non-global zone under
the control of a zone administrator, its contents can no longer be trusted.
As with any file system, there might be setuid binaries, symbolic links, or
otherwise questionable contents that might adversely affect the security of
the global zone. In addition, the <property>mountpoint</property> property
cannot be interpreted in the context of the global zone. Otherwise, the zone
administrator could affect the global zone's namespace. To address the latter,
ZFS uses the <property>zoned</property> property to indicate that a dataset
has been delegated to a non-global zone at one point in time.<indexterm xml:id="indexterm-481">
<primary>zones</primary>
<secondary>
<property>zoned</property> property</secondary>
<tertiary>detailed description</tertiary>
</indexterm>
<indexterm xml:id="indexterm-482">
<primary>
<property>zoned</property> property</primary>
<secondary>detailed description</secondary>
</indexterm>
<indexterm xml:id="indexterm-483">
<primary>ZFS properties</primary>
<secondary>
<property>zoned</property> property</secondary>
<tertiary>detailed description</tertiary>
</indexterm>
</para>
<para>The <property>zoned</property> property is a boolean value that is automatically
turned on when a zone containing a ZFS dataset is first booted. A zone administrator
will not need to manually turn on this property. If the <property>zoned</property> property
is set, the dataset cannot be mounted or shared in the global zone, and is
ignored when the <command>zfs share</command> <option>
a</option> command or
the <command>zfs mount</command> <option>
a</option> command is executed. In
the following example, <filename>tank/zone/zion</filename> has been added
to a zone, while <filename>tank/zone/global</filename> has not:</para>
<screen># <userinput>zfs list -o name,zoned,mountpoint -r tank/zone</userinput>
NAME                  ZONED  MOUNTPOINT
tank/zone/global        off  /tank/zone/global
tank/zone/zion           on  /tank/zone/zion
# <userinput>zfs mount</userinput>
tank/zone/global           /tank/zone/global
tank/zone/zion             /export/zone/zion/root/tank/zone/zion</screen>
<para>Note the difference between the <property>mountpoint</property> property
and the directory where the <filename>tank/zone/zion</filename> dataset is
currently mounted. The <property>mountpoint</property> property reflects the
property as stored on disk, not where the dataset is currently mounted on
the system.</para>
<para>When a dataset is removed from a zone or a zone is destroyed, the <property>zoned</property> property is <emphasis role="strong">not</emphasis> automatically
cleared. This behavior is due to the inherent security risks associated with
these tasks. Because an untrusted user has had complete access to the dataset
and its children, the <property>mountpoint</property> property might be set
to bad values, or setuid binaries might exist on the file systems.</para>
<para>To prevent accidental security risks, the <property>zoned</property> property
must be manually cleared by the global administrator if you want to reuse
the dataset in any way. Before setting the <property>zoned</property> property
to <literal>off</literal>, make sure that the <property>mountpoint</property> property
for the dataset and all its children are set to reasonable values and that
no setuid binaries exist, or turn off the <property>setuid</property> property.</para>
<para>Once you have verified that no security vulnerabilities are left, the <property>zoned</property> property can be turned off by using the <command>zfs set</command> or <command>zfs inherit</command> commands. If the <property>zoned</property> property
is turned off while a dataset is in use within a zone, the system might behave
in unpredictable ways. Only change the property if you are sure the dataset
is no longer in use by a non-global zone.</para>
</sect2>
</sect1>
<sect1 xml:id="gbcgl">
<title>ZFS Alternate Root Pools</title>
<para>When a pool is created, the pool is intrinsically tied to the host system.
The host system maintains knowledge about the pool so that it can detect when
the pool is otherwise unavailable. While useful for normal operation, this
knowledge can prove a hindrance when booting from alternate media, or creating
a pool on removable media. To solve this problem, ZFS provides an <emphasis>alternate
root</emphasis> pool feature. An alternate root pool does not persist across
system reboots, and all mount points are modified to be relative to the root
of the pool.<indexterm xml:id="indexterm-484">
<primary>alternate root pools</primary>
<secondary>opis</secondary>
</indexterm>
<indexterm xml:id="indexterm-485">
<primary>ZFS storage pools</primary>
<secondary>alternate root pools</secondary>
</indexterm>
</para>
<sect2 xml:id="gbdaw">
<title>Creating ZFS Alternate Root Pools</title>
<para>The most common use for creating an alternate root pool is for use with
removable media. In these circumstances, users typically want a single file
system, and they want it to be mounted wherever they choose on the target
system. When an alternate root pool is created by using the <option>
R</option> option,
the mount point of the root file system is automatically set to <filename>/</filename>,
which is the equivalent of the alternate root itself.<indexterm xml:id="indexterm-486">
<primary>alternate root pools</primary>
<secondary>creating</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-487">
<primary>creating</primary>
<secondary>alternate root pools</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a pool called <literal>morpheus</literal> is
created with <filename>/mnt</filename> as the alternate root path:</para>
<screen># <userinput>zpool create -R /mnt morpheus c0t0d0</userinput>
# <userinput>zfs list morpheus</userinput>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
morpheus              32.5K  33.5G     8K  /mnt/</screen>
<para>Note the single file system, <literal>morpheus</literal>, whose mount
point is the alternate root of the pool, <filename>/mnt</filename>. The mount
point that is stored on disk is <filename>/</filename> and the full path to <filename>/mnt</filename> is interpreted only in the context of the alternate root pool.
This file system can then be exported and imported under an arbitrary alternate
root pool on a different system.</para>
</sect2>
<sect2 xml:id="gbdbj">
<title>Importing Alternate Root Pools</title>
<para>Pools can also be imported using an alternate root. This feature allows
for recovery situations, where the mount points should not be interpreted
in context of the current root, but under some temporary directory where repairs
can be performed. This feature also can be used when mounting removable media
as described above.<indexterm xml:id="indexterm-488">
<primary>alternate root pools</primary>
<secondary>importing</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-489">
<primary>importing</primary>
<secondary>alternate root pools</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a pool called <literal>morpheus</literal> is
imported with <filename>/mnt</filename> as the alternate root path. This example
assumes that <literal>morpheus</literal> was previously exported.</para>
<screen># <userinput>zpool import -R /mnt morpheus</userinput>
# <userinput>zpool list morpheus</userinput>
NAME                    SIZE    USED   AVAIL    CAP  HEALTH     ALTROOT
morpheus               33.8G   68.0K   33.7G     0%  ONLINE     /mnt
# <userinput>zfs list morpheus</userinput>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
morpheus              32.5K  33.5G     8K  /mnt/morpheus</screen>
</sect2>
</sect1>
<sect1 xml:id="gbfvq">
<title>ZFS Rights Profiles</title>
<para>If you want to perform ZFS management tasks without using the superuser
(root) account, you can assume a role with either of the following profiles
to perform ZFS administration tasks:<indexterm xml:id="indexterm-490">
<primary>systemy plików ZFS</primary>
<secondary>rights profiles</secondary>
</indexterm>
<indexterm xml:id="indexterm-491">
<primary>ZFS storage pools</primary>
<secondary>rights profiles</secondary>
</indexterm>
<indexterm xml:id="indexterm-492">
<primary>rights profiles</primary>
<secondary>for management of ZFS file systems and storage pools</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<itemizedlist>
<listitem>
<para>ZFS Storage Management – Provides the ability to create,
destroy, and manipulate devices within a ZFS storage pool</para>
</listitem>
<listitem>
<para>ZFS File system Management – Provides the ability to
create, destroy, and modify ZFS file systems</para>
</listitem>
</itemizedlist>
<para>For more information about creating or assigning roles, see <olink targetdoc="819-3321" remap="external">
<citetitle remap="book">System Administration Guide: Security
Services</citetitle>
</olink>.</para>
</sect1>
</chapter>
