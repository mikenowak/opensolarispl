<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML//EN" "docbook.dtd"[
	<!ENTITY % xinclude SYSTEM "xinclude.mod">
	%xinclude;
]>

<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="ftyxh">



<title>ZFS - zagadnienia zaawansowane</title>
<toc>
<para>W tym rozdziale przedstawiono emulowane woluminy, używanie ZFS-a w systemie Solaris
z zainstalowanymi zonami, ZFS-owe alternatywne pule główne oraz ZFS-owe profile praw.</para>
<para>Rozdział składa się z następujących podrozdziałów:</para>
<itemizedlist>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gaypf">Emulowane woluminy</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gayov">Używanie ZFS-a w systemie Solaris z zainstalowanymi zonami</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gbcgl">ZFS-owe alternatywne pule główne</olink>
</para>
</listitem>
<listitem>
<para>
<olink targetdoc="" remap="internal" targetptr="gbfvq">ZFS-owe profile praw</olink>
</para>
</listitem>
</itemizedlist>
</toc>
<sect1 xml:id="gaypf">
<title>Emulowane woluminy</title>
<para><emphasis>Emulowany wolumin</emphasis> to zbiór danych (dataset) reprezentujący
urządzenie blokowe, którego można używać jak każdego innego urządzenia blokowego.  Woluminom tym odpowiadają
pliki urządzeń w katalogu <filename>/dev/zvol/{dsk,rdsk}/path</filename>.<indexterm xml:id="indexterm-461">
<primary>emulowany wolumin</primary>
<secondary>opis</secondary>
</indexterm>
<indexterm xml:id="indexterm-462">
<primary>tworzenie</primary>
<secondary>emulowanego woluminu</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-463">
<primary>systemy plików ZFS</primary>
<secondary>tworzenie emulowanego woluminu</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>Poniższy przykład ilustruje tworzenie ZFS-owego woluminu <filename>tank/vol</filename> o pojemności 5 GB:</para>
<screen># <userinput>zfs create -V 5gb tank/vol</userinput>
</screen>
<para>Podczas tworzenia woluminu, rezerwacja jest automatycznie ustawiana
na rozmiar równy początkowej wielkości woluminu.  Wielkość rezerwacji cały
czas jest równa wielkości woluminu, dzięki czemu nie występują nieprzewidziane
efekty.  Na przykład, jeśli wielkość woluminu zmniejsza się, może
nastąpić uszkodzenie danych.  Należy zachować ostrożność podczas zmniejszania
woluminu.</para>
<para>Jeśli używasz systemu Solaris z zainstalowanymi zonami, nie możesz tworzyć ani klonować ZFS-owego woluminu
w zonie innej niz globalna.  Jakakolwiek próba stworzenia lub sklonowania 
woluminu z strefy innej niż globalna nie powiedzie się.  Więcej
informacji o używaniu ZFS-owych woluminów w globalnej zonie w
<olink targetdoc="" remap="internal" targetptr="gbebi">Dodawanie ZFS-owych woluminów do zon innych niz globalna</olink>.</para>
<sect2 xml:id="gbfvg">
<title>Emulowane woluminy jako urządzenia wymiany (swap) i urządzenia zrzutów awaryjnych</title>
<para>W celu skonfigurowania przestrzeni wymiany należy utworzyć ZFS-owy wolumin o ustalonym rozmiarze
i włączyć wymianę na to urządzenie. Nie należy używać jako urządzenia wymiany pliku w ZFS-owym systemie
plików. Konfiguracja z ZFS-owym plikiem wymiany nie jest obsługiwana.<indexterm xml:id="indexterm-464">
<primary>emulowany wolumin</primary>
<secondary>jako urządzenie wymiany</secondary>
</indexterm>
<indexterm xml:id="indexterm-465">
<primary>tworzenie</primary>
<secondary>emulowanego woluminu jako urządzenia wymiany</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-466">
<primary>ZFS-owe systemy plików</primary>
<secondary>tworzenie emulowanego woluminu jako urządzenia wymiany</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>Poniższy przykład ilustruje dodanie woluminu <filename>tank/vol</filename> wielkości 5 GB
jako urządzenia wymiany.</para>
<screen># <userinput>swap -a /dev/zvol/dsk/tank/vol</userinput>
# <userinput>swap -l</userinput>
swapfile                 dev  swaplo blocks   free
/dev/dsk/c0t0d0s1      32,33      16 1048688  1048688
/dev/zvol/dsk/tank/vol 254,1      16 10485744 10485744</screen>
<para>Używanie woluminu ZFS-a jako urządzenia zrzutów awaryjnych nie jest obsługiwane. W celu
skonfigurowania urządzenia zrzutów awaryjnych należy użyć komendy <command>dumpadm</command>.</para>
</sect2>
</sect1>
<sect1 xml:id="gayov">
<title>Używanie ZFS-a w systemie Solaris z zainstalowanymi zonami</title>
<para>Datasety ZFS-a można dodać do strefy jako ogólny system plików lub jako wydelegowany dataset.</para>
<para>Dodanie systemu plików umożliwia nieglobalnej zonie współdzielenie przestrzeni z zoną globalną, aczkolwiek administrator strefy nie może kontrolować właściwości lub tworzyć nowych systemów plików w hierarchii. Mechanizm ten działa identycznie jak podłączenie do strefy dowolnego innego systemu pliów i powinien być wykorzystywany głównie do współdzielenia miejsca.</para>
<para>ZFS pozwala także na delegację datasetu do nieglobalnej strefy, przekazując administratorowi strefy całkowitą kontrolę nad datasetem i jego potomkami. Administrator strefy może tworzyć i niszczyć systemy plików w tym datasecie i modyfikować właściwości datasetów. Nie może natomiast zmieniać właściwości datasetów, które nie zostały dodane do strefy i nie może przekroczyć limitów najwyższego poziomu ustalonych na wyeksportowanym datasecie.<indexterm xml:id="indexterm-467">
<primary>strefy</primary>
<secondary>używanie z systemami plików ZFS-a</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-468">
<primary>systemy plików ZFS</primary>
<secondary>używanie w systemie Solaris z zainstalowanymi zonami</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<para>Poniższy przypadek opisuje pracę z ZFS-em w systemie Solaris z zainstalowanymi zonami:</para>
<itemizedlist>
<listitem>
<para>Właściwość <command>mountpoint</command> systemu plików ZFS-a dodawanego do nieglobalnej strefy musi mieć wartość legacy.</para>
</listitem>
<listitem>
<para>Kiedy źródłowa <literal>zonepath</literal> i docelowa <literal>zonepath</literal> znajdują się na ZFS-ie i są w tej samej puli, <command>zoneadm clone</command> automatycznie użyje ZFS clone do sklonowana strefy. Komenda <command>zoneadm clone</command> zrzuci obraz ZFS źródłowej <literal>zonepath</literal> i ustawi docelową <literal>zonepath</literal>. Nie należy używać opcji zrzutu obrazu ZFS-a do klonowania strefy. Więcej informacji w <olink targetdoc="819-2450" remap="external" targetptr="zone">Części II, <citetitle remap="chapter">strefy,</citetitle> w <citetitle remap="book">Przewodnik administracji systemu: kontenery Solarisa - zarządzanie zasobami i zonami Solarisa</citetitle>
</olink>.</para>
</listitem>
</itemizedlist>
<sect2 xml:id="gbbrq">
<title>Dodawanie systemu plików ZFS-a do nieglobalnej strefy</title>
<para>Kiedy zakłada się głównie współdzielenie przestrzeni, można dodać system plików ZFS-a jako ogólny system plików. Właściwość <literal>mountpoint</literal> systemu plików ZFS-a dodawanego do nieglobalnej strefy musi być ustawiona na legacy.</para>
<para>Dodawnie systemu plików ZFS-a do nieglobalnej strefy wykonuje się subkomendą <literal>add fs</literal> komendy <command>zonecfg</command>. Na przykład:<indexterm xml:id="indexterm-469">
<primary>strefy</primary>
<secondary>dodawanie systemu plików ZFS-a do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-470">
<primary>dodawanie</primary>
<secondary>systemu plików ZFS-a do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-471">
<primary>systemy plików ZFS</primary>
<secondary>dodawanie systemu plików ZFS-a do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>W poniższym przykładzie globalny administrator dodaje w zonie globalnej system plików ZFS-a do nieglobalnej strefy.</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add fs</userinput>
zonecfg:zion:fs&gt; <userinput>set type=zfs</userinput>
zonecfg:zion:fs&gt; <userinput>set special=tank/zone/zion</userinput>
zonecfg:zion:fs&gt; <userinput>set dir=/export/shared</userinput>
zonecfg:zion:fs&gt; <userinput>end</userinput>
</screen>
<para>Polecenie to dodaje system plików ZFS-a <filename>tank/zone/zion</filename> do strefy <literal>zion</literal> i montuje go w <filename>/export/shared</filename>.
Właściwość <property>mountpoint</property> systemu plików musi być ustawiona na <property>legacy</property>, a sam system plików nie może być wcześniej zamontowany w innej lokalizacji. Administrator strefy może tworzyć i niszczyć pliki w systemie plików. System plików nie może zostać przemontowany w inna lokalizację, a administrator strefy nie może zmienić właściwości systemu plików: atime, readonly, compression itd. Odpowiedzialnym za ustalenie i kontrolę właściwości systemu plióków jest administrator globalnej strefy.</para>
<para>Więcej informacji i komendzie <command>zonecfg</command> i konfiguracji typów zasobów za pomocą <command>zonecfg</command> w <olink targetdoc="819-2450" remap="external" targetptr="zone">Części II, <citetitle remap="chapter">strefy,</citetitle> in <citetitle remap="book">Przewodnik administracji systemu: kontenery Solarisa - zarządzanie zasobami i zonami Solarisa</citetitle>
</olink>.</para>
</sect2>
<sect2 xml:id="gbbst">
<title>Delegowanie datasetów do nieglobalnej strefy</title>
<para>Jeśli głównym celem jest oddelegowanie administrowania nośnikami danych do strefy, wtedy należy skorzystać z możliwości ZFS-a dodania dataestu do strefy za pomocą komendy <command>zonecfg</command> i jej podkomenty <literal>add dataset</literal>.<indexterm xml:id="indexterm-472">
<primary>strefy</primary>
<secondary>delegowanie datasetu do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-473">
<primary>delegowanie</primary>
<secondary>datasetu do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-474">
<primary>systemy plików ZFS</primary>
<secondary>delegowanie datasetu do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>W poniższym przykładzie system plików ZFS-a oddelegowany został do nieglobalnej strefy przez globalnego administratora w globalnej zonie.</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add dataset</userinput>
zonecfg:zion:dataset&gt; <userinput>set name=tank/zone/zion</userinput>
zonecfg:zion:dataset&gt; <userinput>end</userinput>
</screen>
<para>Inaczej niż w przypadku dodania systemu plików, polecenie spowoduje widoczność systemu plików ZFS-a <filename>tank/zone/zion</filename> w zonie <literal>zion</literal>. Administrator strefy może modyfikować właściwości systemu plików i tworzyć potomków. Dodatkowo może wykonywać obrazy systemu plików, klonować i w inny sposób kontrolować całą hierarchię systemu plików.</para>
<para>Więcej informacji o działaniach dozwolonych w zonie w <olink targetdoc="" remap="internal" targetptr="gbbsn">Zarządzenie właściwościami w zonie</olink>.</para>
</sect2>
<sect2 xml:id="gbebi">
<title>Dodawanie woluminu ZFS-a do nieglobalnej strefy</title>
<para>Emoluwane woluminy nie mogą być dodawane do nieglobalnej strefy poleceniem <command>zonecfg</command> <literal>add dataset</literal>. Przy wykryciu próby dodania takiego datasetu zona nie wybootuje. Można jednak dodać woluminy do strefy za pomocą komendy <command>zonecfg</command> i komendy <literal>add device</literal>.<indexterm xml:id="indexterm-475">
<primary>strefy</primary>
<secondary>dodawanie woluminu ZFS-a do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-476">
<primary>dodawanie</primary>
<secondary>woluminu ZFS-a do nieglobalnej strefy</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-477">
<primary>systemy plików ZFS</primary>
<secondary>dodawanie</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>W poniższym przykładzie globalny administrator dodaje do nieglobalnej strefy emulowany wolumin ZFS-a:</para>
<screen># <userinput>zonecfg -z zion</userinput>
zion: No such zone configured
Use 'create' to begin configuring a new zone.
zonecfg:zion&gt; <userinput>create</userinput>
zonecfg:zion&gt; <userinput>add device</userinput>
zonecfg:zion:device&gt; <userinput>set match=/dev/zvol/dsk/tank/vol</userinput>
zonecfg:zion:device&gt; <userinput>end</userinput>
</screen>
<para>Powyższe polecenie eksportuje emulowany wolumin <literal>tank/vol</literal> do strefy. Należy pamiętać, że dodawanie surowego (ang. raw) woluminu do strefy niesie ze sobą zagrożenia bezpieczeństwa, nawet jeśli wolumin nie odpowiada fizycznemu urządzeniu. W szczególności administrator strefy mógłby stworzyć uszkodzone systemy plików, które spowodowałyby panikę systemu przy próbie zamontowania. Więcej informacji o dodawaniu urządzeń do zon i związanych z tym zagrożeniach w <olink targetdoc="" remap="internal" targetptr="gbbre">Znaczenie właściwości <property>zoned</property></olink>.</para>
<para>Więcej informacji o dodawaniu urządzeń do zon w <olink targetdoc="819-2450" remap="external" targetptr="zone">Części II, <citetitle remap="chapter">Zonach,</citetitle> w <citetitle remap="book">Przewodnik administratora systemu: zarządzanie kontenerami i zasobami Solarisa oraz strefy Solarisa</citetitle>
</olink>.</para>
</sect2>
<sect2 xml:id="gbbso">
<title>Używanie puli nośników danych w zonie</title>
<para>Pule nośników danych ZFS-a nie mogą być modyfikowane wewnątrz strefy. Model delegowanej administracji centralizuje kontrolę nad fizycznymi urządzeniami w globalnej strefie, a kontrolę nad nad wirtualnymi nośnikami danych przekazuje do stref nieglobalnych. Wprawdzie można dodać do strefy dataset na poziomie puli, to jednak komendy modyfikujące fizyczne właściwości puli, takie jak tworzenie, dodawanie lub usuwanie są zabronione w strefie. Nawet jeśli do strefy dodano fizyczne nośniki za pomocą komendy <command>zonecfg</command> i <literal>add device</literal> lub jeśli używanie są pliki, komenda <command>zpool</command> odmówi utworzenia nowych pul w strefie.</para>
</sect2>
<sect2 xml:id="gbbsn">
<title>Zarządzanie właściwościami w strefie</title>
<para>Po dodaniu datasetu do strefy administrator strefy ma kontrolę nad poszczególnymi właściwościami datasetu. Wszyscy rodzice datasetu dostępni są tylko w trybie do odczytu, natomiast sam dataset i jego potomkowie są dostępni w trybie do zapisu. Na przykład:<indexterm xml:id="indexterm-478">
<primary>strefy</primary>
<secondary>zarządzanie własciwościami ZFS-a w strefie</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-479">
<primary>właściwości ZFS-a</primary>
<secondary>zarządzanie w strefie</secondary>
<tertiary>opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-480">
<primary>systemy plików ZFS</primary>
<secondary>zarządzanie właściwościami w strefie</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<screen>global# <userinput>zfs list -Ho name</userinput>
tank
tank/home
tank/data
tank/data/matrix
tank/data/zion
tank/data/zion/home</screen>
<para>Jeśli dodano <filename>tank/data/zion</filename> do strefy, każdy z datasetów miałby właściwości.</para>
<informaltable frame="topbot">
<tgroup cols="4" colsep="0" rowsep="0">
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<colspec colwidth="25*"/>
<thead>
<row rowsep="1">
<entry>
<para>Dataset</para>
</entry>
<entry>
<para>Widoczny</para>
</entry>
<entry>
<para>Do zapisu</para>
</entry>
<entry>
<para>Niezmienialne właściwości</para>
</entry>
</row>
</thead>
<tbody>
<row>
<entry>
<para>
<filename>tank</filename>
</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>Nie</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/home</filename>
</para>
</entry>
<entry>
<para>Nie</para>
</entry>
<entry>
<para>-</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data</filename>
</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>Nie</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/matrix</filename>
</para>
</entry>
<entry>
<para>Nie</para>
</entry>
<entry>
<para>-</para>
</entry>
<entry>
<para>-</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/zion</filename>
</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>
<property>sharenfs</property>, <property>zoned</property>, <property>quota</property>, <property>reservation</property>
</para>
</entry>
</row>
<row>
<entry>
<para>
<filename>tank/data/zion/home</filename>
</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>Tak</para>
</entry>
<entry>
<para>
<property>sharenfs</property>, <property>zoned</property>
</para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
<para>Wszyscy rodzice <filename>tank/zone/zion</filename> widoczni są w trybie tylko do odczytu, wszyscy potomkowie w trybie do zapisu a datasety, które nie są cześcią hierarchii rodzic-potomek są zupełnie niewidoczne. Administrator strefy nie może zmienić właściwości <property>sharenfs</property>, ponieważ strefy nieglobalne nie mogą być serwerami NFS. Administrator strefy nie może też zmienić właściwości <literal>zoned</literal>, ponieważ utworzyłoby to lukę w zabezpieczeniach, co wyjaśnimy później.</para>
<para>Zmianom poddają się wszystkie pozostałe właściwości, poza samym datasetem, dla którego właściwości <property>quota</property> i <property>reservation</property> są niezmienialne. Pozwala to administratorowi globalnemu kontrolować zużycie miejsca wszystkich datasetów w nieglobalnych strefach. </para>
<para>Dodatkowo po dodaniu datasetu do nieglobalnej zony właściwości <property>sharenfs</property> i <property>mountpoint</property> nie można zmienić także w strefie globalnej.</para>
</sect2>
<sect2 xml:id="gbbre">
<title>Znaczenie właściwości <property>zoned</property></title>
<para>Przy dodawaniu datasetu do nieglobalnej strefy, musi być on szczególnie oznaczony, aby uniknąć interpretowania niektórych właściwości w kontekście strefy globalnej. Od chwili kiedy dataset został dodany do nieglobalnej strefy i oddany pod kontrolę administratora tej strefy, nie można dłużej zaufać zasobom, które się w nim znajdują. Jak każdy system plików  może zawierać pliki wykonywalne z ustawionym bitem setuid, dowiązania symboliczne lub inne wtpliwe dane, które mogłyby zagrozić bezpieczeństwu globalnej strefy. Dodatkowo nie należy interpretować właściwości <property>mountpoint</property> w kontekście strefy globalnej. Gdyby tak zrobić, administrator strefy mógłby wpływać na przestrzeń nazw globalnej strefy. W związku z tym wprowadzono w ZFS-ie właściwość <property>zoned</property>, która wskazuje, że w pewnym momencie dataset był podłączony do nieglobalnej strefy.<indexterm xml:id="indexterm-481">
<primary>strefy</primary>
<secondary>właściwość 
<property>zoned</property></secondary>
<tertiary>dokładny opis</tertiary>
</indexterm>
<indexterm xml:id="indexterm-482">
<primary>właściwość 
<property>zoned</property></primary>
<secondary>dokładny opis</secondary>
</indexterm>
<indexterm xml:id="indexterm-483">
<primary>właściwości ZFS-a</primary>
<secondary>właściwość 
<property>zoned</property></secondary>
<tertiary>dokładny opis</tertiary>
</indexterm>
</para>
<para>Właściwość <property>zoned</property> to wartość typu boolean automatycznie oznaczana przy pierwszym uruchamianiu strefy zawierającej dataset ZFS-a. Administrator strefy nie musi samodzielnie jest ustawiać. Jeśli właściwość <property>zoned</property> jest ustawiona, dataset nie daje się zamontować lub współdzielić w strefie globalnej i jest ignorowany przy wydawaniu polecenia <command>zfs share</command> <option>a</option> lub <command>zfs mount</command> <option>a</option>. W poniższym przykładzie do strefy dodano <filename>tank/zone/zion</filename>, natomiast <filename>tank/zone/global</filename> nie:</para>
<screen># <userinput>zfs list -o name,zoned,mountpoint -r tank/zone</userinput>
NAME                  ZONED  MOUNTPOINT
tank/zone/global        off  /tank/zone/global
tank/zone/zion           on  /tank/zone/zion
# <userinput>zfs mount</userinput>
tank/zone/global           /tank/zone/global
tank/zone/zion             /export/zone/zion/root/tank/zone/zion</screen>
<para>Należy zwrócić uwagę na właściwość <property>mountpoint</property> i katalog, w którym dataset <filename>tank/zone/zion</filename> jest zamontowany. Właściwość <property>mountpoint</property> odpowiada właściwości na dysku, nie zaś aktualnemu punktowi montowania.</para>
<para>Po wycofaniu datasetu ze strefy lub usunięciu strefy, właściwość <property>zoned</property> <emphasis role="strong">nie jest</emphasis> czyszczona automatycznie. Wynika to z zagrożeń bezpieczeństwa. Niezaufany użytkownik ma całkowity dostęp do datasetu i jego potomków, stąd też właściwość <property>mountpoint</property> może mieć złe ustawienia, bądź w systemie plików mogą istnieć pliki wykonywalne z ustawionym bitem setuid.</para>
<para>W gestii administratora globalnej strefy pozostaje wyłączenie właściwości <property>zoned</property>, w celu uniknięcia przypadkowego zagrożenia bezpieczeństwa, przed ponownym wykorzystaniem datasetu. Przed ustawieniem właściwości <property>zoned</property> na wartość <literal>off</literal>, należy upewnić się, że właściwość <property>mountpoint</property> datasetu i wszystkich jego potomków jest sensownie skonfigurowana i że nie istnieją pliki wykonywalne z ustawionym bitem setuid, bądź należy wyłączyć właściwość <property>setuid</property>.</para>
<para>Po wykluczeniu wszystkich zagrożeń bezpieczeństwa właściwość <property>zoned</property> można wyłączyć komendami <command>zfs set</command> lub <command>zfs inherit</command>. Jeśli wyłączy się właściwość <property>zoned</property> kiedy dataset jest nadal w użyciu w nieglobalnej strefie, system może zachowywać się w nieprzewidywalny sposób. Należy wyłączać ją tylko mając pewność, że dataset nie jest już używany przez żadną nieglobalną strefę.</para>
</sect2>
</sect1>
<sect1 xml:id="gbcgl">
<title>ZFS Alternate Root Pools</title>
<para>When a pool is created, the pool is intrinsically tied to the host system.
The host system maintains knowledge about the pool so that it can detect when
the pool is otherwise unavailable. While useful for normal operation, this
knowledge can prove a hindrance when booting from alternate media, or creating
a pool on removable media. To solve this problem, ZFS provides an <emphasis>alternate
root</emphasis> pool feature. An alternate root pool does not persist across
system reboots, and all mount points are modified to be relative to the root
of the pool.<indexterm xml:id="indexterm-484">
<primary>alternate root pools</primary>
<secondary>opis</secondary>
</indexterm>
<indexterm xml:id="indexterm-485">
<primary>ZFS storage pools</primary>
<secondary>alternate root pools</secondary>
</indexterm>
</para>
<sect2 xml:id="gbdaw">
<title>Creating ZFS Alternate Root Pools</title>
<para>The most common use for creating an alternate root pool is for use with
removable media. In these circumstances, users typically want a single file
system, and they want it to be mounted wherever they choose on the target
system. When an alternate root pool is created by using the <option>
R</option> option,
the mount point of the root file system is automatically set to <filename>/</filename>,
which is the equivalent of the alternate root itself.<indexterm xml:id="indexterm-486">
<primary>alternate root pools</primary>
<secondary>creating</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-487">
<primary>creating</primary>
<secondary>alternate root pools</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a pool called <literal>morpheus</literal> is
created with <filename>/mnt</filename> as the alternate root path:</para>
<screen># <userinput>zpool create -R /mnt morpheus c0t0d0</userinput>
# <userinput>zfs list morpheus</userinput>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
morpheus              32.5K  33.5G     8K  /mnt/</screen>
<para>Note the single file system, <literal>morpheus</literal>, whose mount
point is the alternate root of the pool, <filename>/mnt</filename>. The mount
point that is stored on disk is <filename>/</filename> and the full path to <filename>/mnt</filename> is interpreted only in the context of the alternate root pool.
This file system can then be exported and imported under an arbitrary alternate
root pool on a different system.</para>
</sect2>
<sect2 xml:id="gbdbj">
<title>Importing Alternate Root Pools</title>
<para>Pools can also be imported using an alternate root. This feature allows
for recovery situations, where the mount points should not be interpreted
in context of the current root, but under some temporary directory where repairs
can be performed. This feature also can be used when mounting removable media
as described above.<indexterm xml:id="indexterm-488">
<primary>alternate root pools</primary>
<secondary>importing</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
<indexterm xml:id="indexterm-489">
<primary>importing</primary>
<secondary>alternate root pools</secondary>
<tertiary>(przykład)</tertiary>
</indexterm>
</para>
<para>In the following example, a pool called <literal>morpheus</literal> is
imported with <filename>/mnt</filename> as the alternate root path. This example
assumes that <literal>morpheus</literal> was previously exported.</para>
<screen># <userinput>zpool import -R /mnt morpheus</userinput>
# <userinput>zpool list morpheus</userinput>
NAME                    SIZE    USED   AVAIL    CAP  HEALTH     ALTROOT
morpheus               33.8G   68.0K   33.7G     0%  ONLINE     /mnt
# <userinput>zfs list morpheus</userinput>
NAME                   USED  AVAIL  REFER  MOUNTPOINT
morpheus              32.5K  33.5G     8K  /mnt/morpheus</screen>
</sect2>
</sect1>
<sect1 xml:id="gbfvq">
<title>ZFS Rights Profiles</title>
<para>If you want to perform ZFS management tasks without using the superuser
(root) account, you can assume a role with either of the following profiles
to perform ZFS administration tasks:<indexterm xml:id="indexterm-490">
<primary>systemy plików ZFS</primary>
<secondary>rights profiles</secondary>
</indexterm>
<indexterm xml:id="indexterm-491">
<primary>ZFS storage pools</primary>
<secondary>rights profiles</secondary>
</indexterm>
<indexterm xml:id="indexterm-492">
<primary>rights profiles</primary>
<secondary>for management of ZFS file systems and storage pools</secondary>
<tertiary>opis</tertiary>
</indexterm>
</para>
<itemizedlist>
<listitem>
<para>ZFS Storage Management – Provides the ability to create,
destroy, and manipulate devices within a ZFS storage pool</para>
</listitem>
<listitem>
<para>ZFS File system Management – Provides the ability to
create, destroy, and modify ZFS file systems</para>
</listitem>
</itemizedlist>
<para>For more information about creating or assigning roles, see <olink targetdoc="819-3321" remap="external">
<citetitle remap="book">System Administration Guide: Security
Services</citetitle>
</olink>.</para>
</sect1>
</chapter>
