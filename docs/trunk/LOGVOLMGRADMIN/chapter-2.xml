<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML//EN" "docbook.dtd"[
	<!ENTITY % xinclude SYSTEM "xinclude.mod">
	%xinclude;
]>

<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="storage-overview-1">



<title>Storage
Management Concepts</title>
<toc>
<para>This chapter provides a brief introduction to some common storage management
concepts.</para>
<para>This chapter contains the following information:</para>
<itemizedlist>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-2.xml" targetptr="storage-overview-2">Introduction to Storage Management</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-2.xml" targetptr="config-guide-18145">Configuration Planning Guidelines</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-2.xml" targetptr="config-guide-22088">General Performance Guidelines</olink>
</para>
</listitem>
<listitem>
<para>
<olink remap="internal" targetdoc="chapter-2.xml" targetptr="config-guide-31852">Random I/O and Sequential I/O Optimization</olink>
</para>
</listitem>
</itemizedlist>
</toc>
<sect1 xml:id="storage-overview-2">
<title>Introduction to Storage Management</title>
<para>How you choose to manage your storage determines how you control the
devices that store the active data on your system. To be useful, active data
must be available and remain persistent even after unexpected events, such
as a hardware or software failure.</para>
<sect2 xml:id="storage-overview-9">
<title>Storage Hardware</title>
<para>There are many different devices on which data can be stored. The selection
of devices to best meet your storage needs depends primarily on three factors:</para>
<itemizedlist>
<listitem>
<para>Performance</para>
</listitem>
<listitem>
<para>Availability</para>
</listitem>
<listitem>
<para>Cost</para>
</listitem>
</itemizedlist>
<para>You can use Solaris Volume Manager to help manage the trade-offs in performance,
availability, and cost. You can often mitigate many of the trade-offs with Solaris Volume Manager.</para>
<para>Solaris Volume Manager works well with any supported storage on any system
that runs the Solaris operating system.</para>
</sect2>
<sect2 xml:id="storage-overview-3">
<title>RAID Levels</title>
<para>
<indexterm xml:id="about-metadevices-ix132">
<primary>RAID-5 volume</primary>
<secondary>definition</secondary>
</indexterm>
<indexterm xml:id="about-metadevices-ix133">
<primary>RAID</primary>
<secondary>levels supported in Solaris Volume Manager</secondary>
</indexterm>RAID is an acronym for Redundant Array of Inexpensive (or Independent)
Disks. RAID refers to a set of disks, called an array or a <firstterm>volume</firstterm>,
that appears to the user as a single large disk drive. Depending on the configuration,
this array provides improved reliability, response time, or storage capacity. </para>
<para>Technically, there are six RAID levels, 0-5. Each level refers to a
method of distributing data while ensuring data redundancy. (RAID Level 0
does not provide data redundancy, but is usually included as a RAID classification
anyway. RAID Level 0 provides  the basis for the majority of RAID configurations
in use.) Very few storage environments support RAID Levels 2, 3, and 4, so
those environments are not described here. </para>
<para>Solaris Volume Manager supports the following RAID levels:</para>
<itemizedlist>
<listitem>
<para>
<emphasis role="strong">RAID LEVEL 0</emphasis> – Although
stripes and concatenations do not provide redundancy, these volumes are often
referred to as RAID-0. Basically, data are spread across relatively small,
equally-sized fragments that are allocated alternately and evenly across multiple
physical disks. Any single drive failure can cause data loss. RAID-0 offers
a high data transfer rate and high I/O throughput, but suffers lower reliability
and lower availability than a single disk.</para>
</listitem>
<listitem>
<para>
<emphasis role="strong">RAID Level 1</emphasis> – Mirroring
uses equal amounts of disk capacity to store data and a copy (mirror) of the
data. Data is duplicated, or mirrored, over two or more physical disks. Data
can be read from both drives simultaneously, meaning  that either drive can
service any request, which provides improved performance. If one physical
disk fails, you can continue to use the mirror with no loss in performance
or loss of data. </para>
<para>Solaris Volume Manager supports both RAID-0+1 and (transparently)
RAID-1+0 mirroring, depending on the underlying volumes. See <olink remap="external" targetdoc="chapter-10.xml" targetptr="about-mirrors-7">Providing RAID-1+0 and RAID-0+1</olink> for details.</para>
</listitem>
<listitem>
<para>
<emphasis role="strong">RAID Level 5</emphasis> – RAID-5
uses striping to spread the data over the disks in an array. RAID-5 also records
parity information to provide some data redundancy. A RAID-5 volume can withstand
the failure of an underlying device without failing. If a RAID-5 volume is
used in conjunction with hot spares, the volume can withstand multiple failures
without failing. A RAID-5 volume will have a substantial performance degradation
when operating with a failed device. </para>
<para>In the RAID-5 model, every
device has one area that contains a parity stripe and other areas that contain
data. The parity is spread over all of the disks in the array, which reduces
the write time.  Write time is reduced because  writes do not have to wait
until a dedicated parity disk can accept the data. </para>
</listitem>
</itemizedlist>
</sect2>
</sect1>
<sect1 xml:id="config-guide-18145">
<title>Configuration Planning Guidelines</title>
<para>
<indexterm xml:id="config-guide-ix338">
<primary>configuration planning</primary>
<secondary>overview</secondary>
</indexterm>When you are planning your storage management configuration, keep
in mind that for any given configuration, there are trade-offs in <emphasis>performance</emphasis>, <emphasis>availability</emphasis>, and <emphasis>hardware costs</emphasis>.
You might need to experiment with the different variables to determine what
works best for your configuration. </para>
<para>
<indexterm xml:id="config-guide-ix340">
<primary>configuration planning</primary>
<secondary>guidelines</secondary>
</indexterm>This section provides guidelines for working with the following
types of volumes:</para>
<itemizedlist>
<listitem>
<para>RAID-0 (concatenation and stripe) volumes</para>
</listitem>
<listitem>
<para>RAID-1 (mirror) volumes</para>
</listitem>
<listitem>
<para>RAID-5 volumes</para>
</listitem>
<listitem>
<para>Soft partitions</para>
</listitem>
<listitem>
<para>File systems that are constructed on Solaris Volume Manager volumes</para>
</listitem>
</itemizedlist>
<sect2 xml:id="storage-overview-7">
<title>Choosing Storage</title>
<para>Before you implement your storage management approach, you need to decide
what kinds of storage devices to use. This set of guidelines compares the
various types of storage to help you choose. Additional sets of guidelines
apply to specific types of storage as implemented in Solaris Volume Manager. See
specific chapters about each volume type for details.</para>
<note>

<para>The types of storage that are listed here are not mutually exclusive.
You can use these volumes in combination to meet multiple goals. For example,
you could first create a RAID-1 volume for redundancy. Next, you could create
soft partitions on that RAID-1 volume to increase the possible number of discrete
file systems.</para>
</note>
<para>The following table provides a comparison between the features available
for each type of storage.</para>
<table frame="all" xml:id="storage-overview-tbl-8">

<title>Comparison of Types
of Storage</title>
<tgroup cols="6" colsep="1" rowsep="1">
<colspec colname="colspec0" colwidth="16*"/>
<colspec colname="colspec1" colwidth="16*"/>
<colspec colname="colspec2" colwidth="16*"/>
<colspec colname="colspec3" colwidth="16*"/>
<colspec colname="colspec4" colwidth="16*"/>
<colspec colname="colspec5" colwidth="16*"/>
<thead>
<row>
<entry>
<para>Requirements</para>
</entry>
<entry>
<para>RAID-0 (Concatenation)</para>
</entry>
<entry>
<para>RAID-0 (Stripe)</para>
</entry>
<entry>
<para>RAID-1 (Mirror)</para>
</entry>
<entry>
<para>RAID-5</para>
</entry>
<entry>
<para>Soft Partitions</para>
</entry>
</row>
</thead>
<tbody>
<row>
<entry>
<para>Redundant data</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
</row>
<row>
<entry>
<para>Improved read performance</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>Depends on underlying device</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
</row>
<row>
<entry>
<para>Improved write performance</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
</row>
<row>
<entry>
<para>More than 8 slices per device</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>Yes</para>
</entry>
</row>
<row>
<entry>
<para>Larger available storage space</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
<entry>
<para>Yes</para>
</entry>
<entry>
<para>No</para>
</entry>
</row>
</tbody>
</tgroup>
</table>
<para>The following table outlines the trade-offs in write operations, random
reads, and hardware costs between RAID-1 and RAID–5 volumes.</para>
<table frame="all" xml:id="storage-overview-tbl-9">

<title>Optimizing Redundant
Storage</title>
<tgroup cols="3" colsep="1" rowsep="1">
<colspec colwidth="16*"/>
<colspec colwidth="16*"/>
<colspec colwidth="16*"/>
<thead>
<row>
<entry>
</entry>
<entry>
<para>RAID-1 (Mirror)</para>
</entry>
<entry>
<para>RAID-5</para>
</entry>
</row>
</thead>
<tbody>
<row>
<entry>
<para>Write operations</para>
</entry>
<entry>
<para>Faster</para>
</entry>
<entry>
<para>Slower</para>
</entry>
</row>
<row>
<entry>
<para>Random read</para>
</entry>
<entry>
<para>Faster</para>
</entry>
<entry>
<para>Slower</para>
</entry>
</row>
<row>
<entry>
<para>Hardware cost</para>
</entry>
<entry>
<para>Higher</para>
</entry>
<entry>
<para>Lower</para>
</entry>
</row>
</tbody>
</tgroup>
</table>
<para>The following list summarizes the information outlined in the tables:</para>
<itemizedlist>
<listitem>
<para>RAID-0 volumes (stripes and concatenations) and soft partitions
do not provide any redundancy of data.</para>
</listitem>
<listitem>
<para>Concatenation works well for small random I/O operations.</para>
</listitem>
<listitem>
<para>Striping performs well for large sequential I/O operations
and for random I/O operations.</para>
</listitem>
<listitem>
<para>
<indexterm xml:id="config-guide-ix344">
<primary>mirroring</primary>
<secondary>read and write performance</secondary>
</indexterm>Mirroring might improve read performance, but write performance
is always degraded in mirrors. </para>
</listitem>
<listitem>
<para>Because of the read-modify-write nature of RAID-5 volumes,
volumes with over 20 percent writes should not be RAID-5. If redundancy is
required, consider mirroring.</para>
</listitem>
<listitem>
<para>RAID-5 writes cannot be as fast as mirrored writes, which
in turn cannot be as fast as unprotected writes.</para>
</listitem>
<listitem>
<para>Soft partitions are useful for managing very large storage
devices.</para>
</listitem>
</itemizedlist>
<note>

<para>In addition to these generic storage options, see <olink remap="external" targetdoc="chapter-3.xml" targetptr="basics-41">Hot Spare Pools</olink> for more information about using Solaris Volume Manager to
support redundant devices.</para>
</note>
</sect2>
</sect1>
<sect1 xml:id="config-guide-22088">
<title>General Performance Guidelines</title>
<para>
<indexterm xml:id="config-guide-ix339">
<primary>configuration planning</primary>
<secondary>trade-offs</secondary>
</indexterm>
<indexterm xml:id="config-guide-ix350">
<primary>general performance guidelines</primary>
</indexterm>When you design your storage configuration, consider the following
performance guidelines:</para>
<itemizedlist>
<listitem>
<para>Striping generally has the best performance, but striping
offers no data redundancy. For write-intensive applications, RAID-1 volumes
generally have better performance than RAID-5 volumes.</para>
</listitem>
<listitem>
<para>RAID-1 and RAID-5 volumes both increase data availability,
but both types of volumes generally have lower performance for write operations.
Mirroring does improve random read performance.</para>
</listitem>
<listitem>
<para>RAID-5 volumes have a lower hardware cost than RAID-1 volumes,
while RAID-0 volumes have no additional hardware cost.</para>
</listitem>
<listitem>
<para>Both stripes and RAID-5 volumes distribute data across multiple
disk drives and help balance the I/O load. </para>
</listitem>
<listitem>
<para>Identify the most frequently accessed data, and increase access
bandwidth to that data with mirroring or striping.</para>
</listitem>
<listitem>
<para>Use available performance monitoring capabilities and generic
tools such as the <command>iostat</command> command to identify the most frequently
accessed data. Once identified, the access bandwidth to this data can be increased
using striping, RAID-1 volumes or RAID-5 volumes.</para>
</listitem>
<listitem>
<para>The performance of soft partitions can degrade when the soft
partition size is changed multiple times. </para>
</listitem>
</itemizedlist>
<itemizedlist>
<listitem>
<para>RAID-5 volume performance is lower than stripe performance
for write operations. This performance penalty results from the multiple I/O
operations required to calculate and store the RAID-5 volume parity.</para>
</listitem>
<listitem>
<para>For raw random I/O reads, the stripe and the RAID-5 volume
are comparable. Both the stripe and RAID-5 volumes split the data across multiple
disks. RAID-5 volume parity calculations are not a factor in reads except
after a slice failure.</para>
</listitem>
<listitem>
<para>For raw random I/O writes, the stripe is superior to RAID-5
volumes.</para>
</listitem>
</itemizedlist>
<para>For configuration guidelines specific to Solaris Volume Manager, see <olink remap="external" targetdoc="chapter-3.xml" targetptr="basics-15">Solaris Volume Manager Configuration Guidelines</olink>.</para>
</sect1>
<sect1 xml:id="config-guide-31852">
<title>Random I/O and Sequential I/O Optimization</title>
<indexterm xml:id="config-guide-ix353">
<primary>random I/O</primary>
</indexterm>
<para>
<indexterm xml:id="config-guide-ix354">
<primary>I/O</primary>
</indexterm>This section explains strategies for optimizing your configuration. </para>
<para>If you do not know if sequential I/O or random I/O predominates on the Solaris Volume Manager volumes
you are creating, do not implement these performance tuning tips. These tips
can degrade performance if the tips are improperly implemented.</para>
<para>The following optimization suggestions assume that you are optimizing
a RAID-0 volume. In general, you would want to optimize a RAID-0 volume, then
mirror that volume to provide both optimal performance and data redundancy. </para>
<sect2 xml:id="config-guide-8">
<title>Random I/O</title>
<para>In a random I/O environment, such as an environment used for databases
and general-purpose file servers, all disks should spend equal amounts of
time servicing I/O requests. </para>
<para>For example, assume that you have 40 Gbytes of storage for a database
application. If you stripe across four 10 Gbyte disk spindles, and if the
I/O is random and evenly dispersed across the volume, then each of the disks
will be equally busy, which generally improves performance.</para>
<para>The target for maximum random I/O performance on a disk is 35 percent
or lower usage, as reported by the <command>iostat</command> command. Disk
use in excess of 65 percent on a typical basis is a problem. Disk use in excess
of 90 percent is a significant problem. The solution to having disk use values
that are too high is to create a new RAID-0 volume with more disks (spindles). </para>
<note>

<para>Simply attaching additional disks to an existing volume cannot
improve performance. You must create a new volume with the ideal parameters
to optimize performance.</para>
</note>
<para>The interlace size of the stripe does not matter because you just want
to spread the data across all the disks. Any interlace value greater than
the typical I/O request will suffice.</para>
</sect2>
<sect2 xml:id="config-guide-9">
<title>Sequential Access I/O</title>
<para>
<indexterm xml:id="config-guide-ix355">
<primary>sequential I/O</primary>
</indexterm>You can optimize the performance of your configuration in a sequential
I/O environment, such as DBMS servers that are dominated by full table scans
and NFS servers in very data-intensive environments. To take advantage of
a sequential I/O environment, set the interlace value low relative to the
size of the typical I/O request.</para>
<para>For example, assume a typical I/O request size of 256 Kbytes and striping
across 4 spindles. A good choice for the stripe unit size in this example
would be: </para>
<para>256 Kbytes / 4 = 64 Kbytes, or smaller</para>
<para>This strategy ensures that the typical I/O request is spread across
multiple disk spindles, thus increasing the sequential bandwidth. </para>
<note>

<para>Seek time and rotation time are practically zero in the sequential
I/O environment. When you optimize sequential I/O, the internal transfer rate
of a disk is most important.</para>
</note>
<para>In sequential applications, the typical I/O size is usually large, meaning
more  than 128 Kbytes or even more than 1 Mbyte. Assume an application with
a typical I/O request size of  2 Mbytes and
assume striping across 4 disk spindles, thus: </para>
<para>2048 Kbytes / 4 = 512 Kbytes</para>
<para>So, a good choice for the interlace size would be 256–512
Kbytes.</para>
</sect2>
</sect1>
</chapter>
